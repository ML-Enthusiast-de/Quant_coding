{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd51c7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "PROJECT_ROOT = os.path.abspath(\"..\")\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import optuna\n",
    "from sklearn.metrics import mean_squared_error, log_loss\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, confusion_matrix\n",
    "\n",
    "from src.data_loading import download_daily_prices, load_daily_close\n",
    "from src.signals import (\n",
    "    make_basic_signals,\n",
    "    build_feature_matrix,\n",
    "    build_sequence_dataset,\n",
    "    DEFAULT_FEATURES,\n",
    ")\n",
    "from src.models_tree import train_tree_regressor, evaluate_regression\n",
    "from src.models_lstm_class import train_lstm_classifier, predict_lstm_proba\n",
    "from src.models_lstm import train_lstm_regressor, predict_lstm\n",
    "from src.backtest import (\n",
    "    equity_curve_from_returns,\n",
    "    cagr,\n",
    "    annualized_vol,\n",
    "    sharpe_ratio,\n",
    "    max_drawdown,\n",
    ")\n",
    "from src.models_tcn import train_tcn_regressor, predict_tcn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953d972c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpe_ratio_np(returns: np.ndarray, freq: int = 252) -> float:\n",
    "    \"\"\"Simple annualized Sharpe on a 1D array of daily returns.\"\"\"\n",
    "    mean = returns.mean()\n",
    "    std = returns.std()\n",
    "    if std == 0:\n",
    "        return 0.0\n",
    "    return np.sqrt(freq) * mean / std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dc4ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = \"SPY\"\n",
    "\n",
    "# Load or download prices\n",
    "try:\n",
    "    prices = load_daily_close(ticker)\n",
    "except FileNotFoundError:\n",
    "    download_daily_prices(ticker, start=\"2010-01-01\")\n",
    "    prices = load_daily_close(ticker)\n",
    "\n",
    "signals_df = make_basic_signals(prices)\n",
    "signals_df.head(), signals_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0ff736",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = DEFAULT_FEATURES\n",
    "\n",
    "X, y, dates = build_feature_matrix(signals_df, feature_names)\n",
    "\n",
    "split_idx = int(len(X) * 0.7)  # 70% train / 30% test\n",
    "\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train_float, y_test_float = y[:split_idx], y[split_idx:]\n",
    "dates_train, dates_test = dates[:split_idx], dates[split_idx:]\n",
    "\n",
    "print(\"Train size:\", len(X_train), \"Test size:\", len(X_test))\n",
    "print(\"Train period:\", dates_train[0], \"->\", dates_train[-1])\n",
    "print(\"Test period:\", dates_test[0], \"->\", dates_test[-1])\n",
    "\n",
    "# Standardise features for LSTM regressor\n",
    "scaler_X = StandardScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled  = scaler_X.transform(X_test)\n",
    "X_train_scaled.shape, X_test_scaled.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200d1b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Optuna tuning: Tree model (Sharpe-based)\n",
    "# ---------------------------\n",
    "def objective_tree(trial):\n",
    "    # Hyperparameters of the tree\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 2, 8)\n",
    "    max_iter = trial.suggest_int(\"max_iter\", 100, 500)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 0.2, log=True)\n",
    "    l2_reg = trial.suggest_float(\"l2_regularization\", 0.0, 1.0)\n",
    "\n",
    "    # Trading hyperparameter: quantile for threshold\n",
    "    q = trial.suggest_float(\"q\", 0.4, 0.9)  # e.g. 40%–90% quantile\n",
    "\n",
    "    # Chronological split of X_train into inner-train / validation\n",
    "    n = len(X_train)\n",
    "    split = int(n * 0.8)\n",
    "    X_tr, X_val = X_train[:split], X_train[split:]\n",
    "    y_tr, y_val = y_train_float[:split], y_train_float[split:]\n",
    "\n",
    "    # Train tree on inner-train\n",
    "    model = train_tree_regressor(\n",
    "        X_tr,\n",
    "        y_tr,\n",
    "        max_depth=max_depth,\n",
    "        max_iter=max_iter,\n",
    "        learning_rate=learning_rate,\n",
    "        l2_regularization=l2_reg,\n",
    "    )\n",
    "\n",
    "    # Predict on inner-val\n",
    "    preds_val = model.predict(X_val)\n",
    "\n",
    "    # Ranking rule on validation:\n",
    "    # only long when prediction is above q-quantile of preds_val\n",
    "    tau_val = np.quantile(preds_val, q)\n",
    "    positions_val = (preds_val > tau_val).astype(int)\n",
    "    strat_ret_val = positions_val * y_val  # actual next-day returns\n",
    "\n",
    "    # Strategy Sharpe on validation slice\n",
    "    sharpe_val = sharpe_ratio_np(strat_ret_val)\n",
    "\n",
    "    # Optuna minimizes -> return negative Sharpe\n",
    "    return -sharpe_val\n",
    "\n",
    "\n",
    "\n",
    "study_tree = optuna.create_study(direction=\"minimize\")\n",
    "study_tree.optimize(objective_tree, n_trials=10)\n",
    "\n",
    "print(\"Best tree params:\", study_tree.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6648b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Tree with best Optuna params (model + trading rule) ---\n",
    "best_tree_params = study_tree.best_params\n",
    "q_tree = best_tree_params[\"q\"]\n",
    "\n",
    "# Params for the sklearn model (exclude q)\n",
    "tree_model_params = {k: v for k, v in best_tree_params.items() if k != \"q\"}\n",
    "\n",
    "tree_model = train_tree_regressor(\n",
    "    X_train,\n",
    "    y_train_float,\n",
    "    **tree_model_params,\n",
    ")\n",
    "\n",
    "# Predictions on train/test\n",
    "preds_tree_train = tree_model.predict(X_train)\n",
    "preds_tree_test  = tree_model.predict(X_test)\n",
    "\n",
    "# Threshold based on train predictions and tuned q\n",
    "tau_tree = np.quantile(preds_tree_train, q_tree)\n",
    "print(\"Tree q_best:\", q_tree, \" -> tau_tree:\", tau_tree)\n",
    "\n",
    "# Trading rule on test\n",
    "positions_tree = (preds_tree_test > tau_tree).astype(int)\n",
    "\n",
    "# Returns on full test period\n",
    "bh_returns = y_test_float                              # buy & hold\n",
    "tree_returns = positions_tree * y_test_float           # tree strategy\n",
    "\n",
    "# Series for full test period (we'll align later)\n",
    "bh_series_full = signals_df[\"target_ret_1\"].iloc[split_idx:].copy()\n",
    "bh_series_full[:] = bh_returns\n",
    "\n",
    "tree_series_full = bh_series_full.copy()\n",
    "tree_series_full[:] = tree_returns\n",
    "\n",
    "\n",
    "bh_series_full.head(), tree_series_full.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3473af55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direction labels for single-day features (no sequences)\n",
    "y_train_class_simple = (y_train_float > 0).astype(int)\n",
    "y_test_class_simple  = (y_test_float > 0).astype(int)\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train, y_train_class_simple)\n",
    "\n",
    "y_pred_simple = log_reg.predict(X_test)\n",
    "\n",
    "base_rate_simple = y_test_class_simple.mean()\n",
    "acc_simple = accuracy_score(y_test_class_simple, y_pred_simple)\n",
    "bacc_simple = balanced_accuracy_score(y_test_class_simple, y_pred_simple)\n",
    "\n",
    "print(\"Base rate (simple):\", base_rate_simple)\n",
    "print(\"LogReg accuracy:\", acc_simple)\n",
    "print(\"LogReg balanced acc:\", bacc_simple)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2883d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 30\n",
    "\n",
    "# --- Sequences for CLASSIFIER (unscaled features) ---\n",
    "X_train_seq, y_train_seq_float, dates_train_seq = build_sequence_dataset(\n",
    "    X_train, y_train_float, dates_train, seq_len=seq_len\n",
    ")\n",
    "X_test_seq, y_test_seq_float, dates_test_seq = build_sequence_dataset(\n",
    "    X_test, y_test_float, dates_test, seq_len=seq_len\n",
    ")\n",
    "\n",
    "# Labels for classifier\n",
    "y_train_seq_class = (y_train_seq_float > 0).astype(np.float32)\n",
    "y_test_seq_class  = (y_test_seq_float > 0).astype(np.float32)\n",
    "\n",
    "print(\"Classifier sequences:\", X_train_seq.shape, X_test_seq.shape)\n",
    "print(\"Fraction up days (train/test):\", y_train_seq_class.mean(), y_test_seq_class.mean())\n",
    "\n",
    "# --- Sequences for REGRESSOR (scaled features) ---\n",
    "X_train_seq_reg, y_train_seq_reg_float, dates_train_seq_reg = build_sequence_dataset(\n",
    "    X_train_scaled, y_train_float, dates_train, seq_len=seq_len\n",
    ")\n",
    "X_test_seq_reg, y_test_seq_reg_float, dates_test_seq_reg = build_sequence_dataset(\n",
    "    X_test_scaled, y_test_float, dates_test, seq_len=seq_len\n",
    ")\n",
    "\n",
    "print(\"Regressor sequences:\", X_train_seq_reg.shape, X_test_seq_reg.shape)\n",
    "print(\"First test seq date (cls/reg):\", dates_test_seq[0], dates_test_seq_reg[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fa0a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Optuna tuning: LSTM Classifier\n",
    "# ---------------------------\n",
    "def objective_lstm_cls(trial):\n",
    "    hidden_dim = trial.suggest_int(\"hidden_dim\", 16, 64)\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 10)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 5e-3, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128])\n",
    "    num_epochs = trial.suggest_int(\"num_epochs\", 10, 40)\n",
    "\n",
    "    n = len(X_train_seq)\n",
    "    split = int(n * 0.7)\n",
    "    X_tr_seq = X_train_seq[:split]\n",
    "    X_val_seq = X_train_seq[split:]\n",
    "    y_tr_seq = y_train_seq_class[:split]\n",
    "    y_val_seq = y_train_seq_class[split:]\n",
    "\n",
    "    model = train_lstm_classifier(\n",
    "        X_tr_seq,\n",
    "        y_tr_seq,\n",
    "        num_epochs=num_epochs,\n",
    "        batch_size=batch_size,\n",
    "        lr=lr,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "    )\n",
    "\n",
    "    p_up_val = predict_lstm_proba(model, X_val_seq)\n",
    "    # Log-loss on validation as objective\n",
    "    loss_val = log_loss(y_val_seq, p_up_val)\n",
    "    return loss_val\n",
    "\n",
    "\n",
    "study_lstm_cls = optuna.create_study(direction=\"minimize\")\n",
    "study_lstm_cls.optimize(objective_lstm_cls, n_trials=10)\n",
    "\n",
    "print(\"Best LSTM cls params:\", study_lstm_cls.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777d5296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Optuna tuning: LSTM Regressor (Sharpe-based)\n",
    "# ---------------------------\n",
    "def objective_lstm_reg(trial):\n",
    "    hidden_dim = trial.suggest_int(\"hidden_dim\", 16, 64)\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 10)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 5e-3, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128])\n",
    "    num_epochs = trial.suggest_int(\"num_epochs\", 15, 40)\n",
    "    q = trial.suggest_float(\"q\", 0.5, 0.9)  # ⬅️ quantile for trading threshold\n",
    "\n",
    "    # Chronological inner train/val split on *sequences*\n",
    "    n = len(X_train_seq_reg)\n",
    "    split = int(n * 0.7)\n",
    "    X_tr_seq = X_train_seq_reg[:split]\n",
    "    X_val_seq = X_train_seq_reg[split:]\n",
    "    y_tr_seq = y_train_seq_reg_float[:split]\n",
    "    y_val_seq = y_train_seq_reg_float[split:]\n",
    "    dates_val_seq = dates_train_seq_reg[split:]\n",
    "\n",
    "    # Train model on inner-train\n",
    "    model = train_lstm_regressor(\n",
    "        X_tr_seq,\n",
    "        y_tr_seq,\n",
    "        num_epochs=num_epochs,\n",
    "        batch_size=batch_size,\n",
    "        lr=lr,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "    )\n",
    "\n",
    "    # Predictions on inner-val\n",
    "    preds_val = predict_lstm(model, X_val_seq)\n",
    "\n",
    "    # Trading rule on inner-val: rank by predicted return\n",
    "    tau_ret_val = np.quantile(preds_val, q)\n",
    "    positions_val = (preds_val > tau_ret_val).astype(int)\n",
    "    strat_ret_val = positions_val * y_val_seq  # use true next-day returns\n",
    "\n",
    "    # Compute Sharpe on validation slice\n",
    "    sharpe_val = sharpe_ratio_np(strat_ret_val)\n",
    "\n",
    "    # Optuna minimizes -> return negative Sharpe\n",
    "    return -sharpe_val\n",
    "\n",
    "\n",
    "\n",
    "study_lstm_reg = optuna.create_study(direction=\"minimize\")\n",
    "study_lstm_reg.optimize(objective_lstm_reg, n_trials=10)\n",
    "\n",
    "print(\"Best LSTM reg params:\", study_lstm_reg.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747240eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Optuna tuning: TCN Regressor (Sharpe-based, with q)\n",
    "# ---------------------------\n",
    "def objective_tcn_reg(trial):\n",
    "    hidden_dim = trial.suggest_int(\"hidden_dim\", 16, 64)\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 3)\n",
    "    kernel_size = trial.suggest_int(\"kernel_size\", 2, 5)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 5e-3, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128])\n",
    "    num_epochs = trial.suggest_int(\"num_epochs\", 10, 40)\n",
    "    q = trial.suggest_float(\"q\", 0.5, 0.9)  # quantile for trading threshold\n",
    "\n",
    "    # Chronological inner train/val split on *sequences*\n",
    "    n = len(X_train_seq_reg)\n",
    "    split = int(n * 0.7)  # match LSTM reg split\n",
    "    X_tr_seq = X_train_seq_reg[:split]\n",
    "    X_val_seq = X_train_seq_reg[split:]\n",
    "    y_tr_seq = y_train_seq_reg_float[:split]\n",
    "    y_val_seq = y_train_seq_reg_float[split:]\n",
    "\n",
    "    # Train TCN on inner-train\n",
    "    model = train_tcn_regressor(\n",
    "        X_tr_seq,\n",
    "        y_tr_seq,\n",
    "        num_epochs=num_epochs,\n",
    "        batch_size=batch_size,\n",
    "        lr=lr,\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        kernel_size=kernel_size,\n",
    "        dropout=0.1,\n",
    "    )\n",
    "\n",
    "    # Predictions on inner-val\n",
    "    preds_val = predict_tcn(model, X_val_seq)\n",
    "\n",
    "    # Ranking rule on validation: long on top (1-q) of predictions\n",
    "    tau_ret_val = np.quantile(preds_val, q)\n",
    "    positions_val = (preds_val > tau_ret_val).astype(int)\n",
    "    strat_ret_val = positions_val * y_val_seq\n",
    "\n",
    "    sharpe_val = sharpe_ratio_np(strat_ret_val)\n",
    "\n",
    "    # Optuna minimizes -> negative Sharpe\n",
    "    return -sharpe_val\n",
    "\n",
    "\n",
    "\n",
    "study_tcn_reg = optuna.create_study(direction=\"minimize\")\n",
    "study_tcn_reg.optimize(objective_tcn_reg, n_trials=10)\n",
    "\n",
    "print(\"Best TCN reg params:\", study_tcn_reg.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3854d52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tcn_params = study_tcn_reg.best_params\n",
    "\n",
    "# Separate q from the model hyperparameters\n",
    "q_tcn_best = best_tcn_params[\"q\"]\n",
    "tcn_model_params = {k: v for k, v in best_tcn_params.items() if k != \"q\"}\n",
    "\n",
    "tcn_reg = train_tcn_regressor(\n",
    "    X_train_seq_reg,\n",
    "    y_train_seq_reg_float,\n",
    "    num_epochs=tcn_model_params[\"num_epochs\"],\n",
    "    batch_size=tcn_model_params[\"batch_size\"],\n",
    "    lr=tcn_model_params[\"lr\"],\n",
    "    hidden_dim=tcn_model_params[\"hidden_dim\"],\n",
    "    num_layers=tcn_model_params[\"num_layers\"],\n",
    "    kernel_size=tcn_model_params[\"kernel_size\"],\n",
    "    dropout=0.1,\n",
    ")\n",
    "\n",
    "preds_train_tcn = predict_tcn(tcn_reg, X_train_seq_reg)\n",
    "preds_test_tcn  = predict_tcn(tcn_reg, X_test_seq_reg)\n",
    "\n",
    "print(\"TCN Train preds mean/std:\",\n",
    "      float(preds_train_tcn.mean()), float(preds_train_tcn.std()))\n",
    "print(\"TCN Test  preds mean/std:\",\n",
    "      float(preds_test_tcn.mean()), float(preds_test_tcn.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069ea180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking rule: use tuned q on train preds\n",
    "tau_ret_tcn = np.quantile(preds_train_tcn, q_tcn_best)\n",
    "print(\"TCN q_best:\", q_tcn_best, \" -> tau_ret_tcn:\", tau_ret_tcn)\n",
    "\n",
    "positions_tcn = (preds_test_tcn > tau_ret_tcn).astype(int)\n",
    "print(\"TCN long ratio:\", float((positions_tcn == 1).mean()))\n",
    "print(\"TCN trades:\", int((positions_tcn[1:] != positions_tcn[:-1]).sum()))\n",
    "\n",
    "# Strategy returns\n",
    "tcn_returns = positions_tcn * y_test_seq_reg_float\n",
    "\n",
    "# Series for TCN strategy\n",
    "tcn_series = signals_df[\"target_ret_1\"].loc[dates_test_seq_reg].copy()\n",
    "tcn_series[:] = tcn_returns\n",
    "tcn_series.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed15cee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cls_params = study_lstm_cls.best_params\n",
    "\n",
    "lstm_clf = train_lstm_classifier(\n",
    "    X_train_seq,\n",
    "    y_train_seq_class,\n",
    "    num_epochs=best_cls_params[\"num_epochs\"],\n",
    "    batch_size=best_cls_params[\"batch_size\"],\n",
    "    lr=best_cls_params[\"lr\"],\n",
    "    hidden_dim=best_cls_params[\"hidden_dim\"],\n",
    "    num_layers=best_cls_params[\"num_layers\"],\n",
    ")\n",
    "\n",
    "\n",
    "# Probabilities on train & test\n",
    "p_up_train = predict_lstm_proba(lstm_clf, X_train_seq)\n",
    "p_up_test  = predict_lstm_proba(lstm_clf, X_test_seq)\n",
    "\n",
    "print(\"Train p_up mean/std:\", float(p_up_train.mean()), float(p_up_train.std()))\n",
    "print(\"Test  p_up mean/std:\", float(p_up_test.mean()), float(p_up_test.std()))\n",
    "\n",
    "# Threshold on train distribution to define when we trade\n",
    "tau = np.quantile(p_up_train, 0.7)   # only top 30% most bullish\n",
    "print(\"tau (prob threshold):\", tau)\n",
    "\n",
    "positions_lstm_cls = (p_up_test > tau).astype(int)\n",
    "print(\"LSTM classifier long ratio:\", float((positions_lstm_cls == 1).mean()))\n",
    "\n",
    "# Strategy returns (use float next-day returns)\n",
    "lstm_cls_returns = positions_lstm_cls * y_test_seq_float\n",
    "\n",
    "# Series for classifier strategy\n",
    "lstm_cls_series = signals_df[\"target_ret_1\"].loc[dates_test_seq].copy()\n",
    "lstm_cls_series[:] = lstm_cls_returns\n",
    "\n",
    "lstm_cls_series.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00daccf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_reg_params = study_lstm_reg.best_params\n",
    "\n",
    "lstm_reg = train_lstm_regressor(\n",
    "    X_train_seq_reg,\n",
    "    y_train_seq_reg_float,\n",
    "    num_epochs=best_reg_params[\"num_epochs\"],\n",
    "    batch_size=best_reg_params[\"batch_size\"],\n",
    "    lr=best_reg_params[\"lr\"],\n",
    "    hidden_dim=best_reg_params[\"hidden_dim\"],\n",
    "    num_layers=best_reg_params[\"num_layers\"],\n",
    ")\n",
    "\n",
    "preds_train_reg = predict_lstm(lstm_reg, X_train_seq_reg)\n",
    "preds_test_reg  = predict_lstm(lstm_reg, X_test_seq_reg)\n",
    "\n",
    "print(\"Train preds mean/std:\", float(preds_train_reg.mean()), float(preds_train_reg.std()))\n",
    "print(\"Test  preds mean/std:\", float(preds_test_reg.mean()), float(preds_test_reg.std()))\n",
    "\n",
    "# Use the tuned q to define tau_ret on *train* preds\n",
    "q_best = best_reg_params[\"q\"]\n",
    "tau_ret = np.quantile(preds_train_reg, q_best)\n",
    "print(\"q_best:\", q_best, \" -> tau_ret:\", tau_ret)\n",
    "\n",
    "positions_lstm_reg = (preds_test_reg > tau_ret).astype(int)\n",
    "print(\"LSTM reg long ratio:\", float((positions_lstm_reg == 1).mean()))\n",
    "print(\"LSTM reg trades:\", int((positions_lstm_reg[1:] != positions_lstm_reg[:-1]).sum()))\n",
    "\n",
    "lstm_reg_returns = positions_lstm_reg * y_test_seq_reg_float\n",
    "lstm_reg_series = signals_df[\"target_ret_1\"].loc[dates_test_seq_reg].copy()\n",
    "lstm_reg_series[:] = lstm_reg_returns\n",
    "\n",
    "\n",
    "lstm_reg_series.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb05ada1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common date range for all four strategies\n",
    "common_idx = (\n",
    "    bh_series_full.index\n",
    "    .intersection(tree_series_full.index)\n",
    "    .intersection(lstm_cls_series.index)\n",
    "    .intersection(lstm_reg_series.index)\n",
    "    .intersection(tcn_series.index)\n",
    ")\n",
    "\n",
    "bh_common       = bh_series_full.loc[common_idx]\n",
    "tree_common     = tree_series_full.loc[common_idx]\n",
    "lstm_cls_common = lstm_cls_series.loc[common_idx]\n",
    "lstm_reg_common = lstm_reg_series.loc[common_idx]\n",
    "tcn_common      = tcn_series.loc[common_idx]\n",
    "\n",
    "equity_bh        = equity_curve_from_returns(bh_common)\n",
    "equity_tree      = equity_curve_from_returns(tree_common)\n",
    "equity_lstm_cls  = equity_curve_from_returns(lstm_cls_common)\n",
    "equity_lstm_reg  = equity_curve_from_returns(lstm_reg_common)\n",
    "equity_tcn       = equity_curve_from_returns(tcn_common)\n",
    "\n",
    "\n",
    "metrics = {\n",
    "    \"bh_cagr\":        cagr(equity_bh),\n",
    "    \"bh_vol\":         annualized_vol(bh_common),\n",
    "    \"bh_sharpe\":      sharpe_ratio(bh_common),\n",
    "    \"bh_max_dd\":      max_drawdown(equity_bh),\n",
    "\n",
    "    \"tree_cagr\":      cagr(equity_tree),\n",
    "    \"tree_vol\":       annualized_vol(tree_common),\n",
    "    \"tree_sharpe\":    sharpe_ratio(tree_common),\n",
    "    \"tree_max_dd\":    max_drawdown(equity_tree),\n",
    "\n",
    "    \"lstm_cls_cagr\":   cagr(equity_lstm_cls),\n",
    "    \"lstm_cls_vol\":    annualized_vol(lstm_cls_common),\n",
    "    \"lstm_cls_sharpe\": sharpe_ratio(lstm_cls_common),\n",
    "    \"lstm_cls_max_dd\": max_drawdown(equity_lstm_cls),\n",
    "\n",
    "    \"lstm_reg_cagr\":   cagr(equity_lstm_reg),\n",
    "    \"lstm_reg_vol\":    annualized_vol(lstm_reg_common),\n",
    "    \"lstm_reg_sharpe\": sharpe_ratio(lstm_reg_common),\n",
    "    \"lstm_reg_max_dd\": max_drawdown(equity_lstm_reg),\n",
    "\n",
    "    \"tcn_cagr\":        cagr(equity_tcn),\n",
    "    \"tcn_vol\":         annualized_vol(tcn_common),\n",
    "    \"tcn_sharpe\":      sharpe_ratio(tcn_common),\n",
    "    \"tcn_max_dd\":      max_drawdown(equity_tcn),\n",
    "}\n",
    "metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8945bd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "best_params_all = {\n",
    "    \"tree\":      study_tree.best_params,\n",
    "    \"lstm_reg\":  study_lstm_reg.best_params,\n",
    "    \"lstm_cls\":  study_lstm_cls.best_params,\n",
    "    \"tcn_reg\":   study_tcn_reg.best_params,\n",
    "}\n",
    "\n",
    "config_path = Path(PROJECT_ROOT) / \"configs\"\n",
    "config_path.mkdir(exist_ok=True)\n",
    "\n",
    "with open(config_path / \"best_params_spy.json\", \"w\") as f:\n",
    "    json.dump(best_params_all, f, indent=2)\n",
    "\n",
    "best_params_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4ba9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "equity_bh.plot(label=\"Buy & Hold\")\n",
    "equity_tree.plot(label=\"Tree Strategy\")\n",
    "equity_lstm_cls.plot(label=\"LSTM Classifier\")\n",
    "equity_lstm_reg.plot(label=\"LSTM Regressor (ranking)\")\n",
    "equity_tcn.plot(label=\"TCN Regressor (ranking)\")\n",
    "plt.legend()\n",
    "plt.title(f\"{ticker} – equity curves (test period, seq_len={seq_len})\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec519c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Final performance report ===\n",
    "\n",
    "# 1) Align position series with the common index used for returns\n",
    "idx_test_full = signals_df.index[split_idx:]\n",
    "\n",
    "# Buy & Hold: always long\n",
    "pos_bh = pd.Series(1, index=idx_test_full).loc[common_idx]\n",
    "\n",
    "# Tree positions (one per test day)\n",
    "pos_tree_series = pd.Series(positions_tree, index=idx_test_full).loc[common_idx]\n",
    "\n",
    "# LSTM classifier positions (indexed by dates_test_seq)\n",
    "pos_lstm_cls_series = pd.Series(positions_lstm_cls, index=dates_test_seq).loc[common_idx]\n",
    "\n",
    "# LSTM regressor positions (indexed by dates_test_seq_reg)\n",
    "pos_lstm_reg_series = pd.Series(positions_lstm_reg, index=dates_test_seq_reg).loc[common_idx]\n",
    "\n",
    "# TCN regressor positions (indexed by dates_test_seq_reg)\n",
    "pos_tcn_series = pd.Series(positions_tcn, index=dates_test_seq_reg).loc[common_idx]\n",
    "\n",
    "\n",
    "def long_ratio_and_trades(pos_series: pd.Series) -> tuple[float, int]:\n",
    "    \"\"\"Fraction of days long, and number of position changes.\"\"\"\n",
    "    vals = pos_series.values\n",
    "    long_ratio = float((vals == 1).mean())\n",
    "    trades = int((vals[1:] != vals[:-1]).sum())\n",
    "    return long_ratio, trades\n",
    "\n",
    "\n",
    "rows = []\n",
    "for name, returns, pos in [\n",
    "    (\"Buy & Hold\",       bh_common,       pos_bh),\n",
    "    (\"Tree\",             tree_common,     pos_tree_series),\n",
    "    (\"LSTM Classifier\",  lstm_cls_common, pos_lstm_cls_series),\n",
    "    (\"LSTM Regressor\",   lstm_reg_common, pos_lstm_reg_series),\n",
    "    (\"TCN Regressor\",    tcn_common,      pos_tcn_series),\n",
    "]:\n",
    "    lr, n_trades = long_ratio_and_trades(pos)\n",
    "    eq = equity_curve_from_returns(returns)\n",
    "    rows.append({\n",
    "        \"Strategy\":   name,\n",
    "        \"CAGR\":       cagr(eq),\n",
    "        \"Vol\":        annualized_vol(returns),\n",
    "        \"Sharpe\":     sharpe_ratio(returns),\n",
    "        \"MaxDD\":      max_drawdown(eq),\n",
    "        \"LongRatio\":  lr,\n",
    "        \"Trades\":     n_trades,\n",
    "    })\n",
    "\n",
    "performance_df = pd.DataFrame(rows).set_index(\"Strategy\")\n",
    "performance_df.round(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbb595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Training / Optuna summary ===\n",
    "\n",
    "train_rows = [\n",
    "    {\n",
    "        \"Model\": \"Tree (reg + ranking)\",\n",
    "        \"Objective\": \"Sharpe\",\n",
    "        \"BestValObj\": -study_tree.best_value,  # this is the best *Sharpe*\n",
    "        \"BestParams\": study_tree.best_params,\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"LSTM Reg (ranking)\",\n",
    "        \"Objective\": \"Sharpe\",\n",
    "        \"BestValObj\": -study_lstm_reg.best_value,\n",
    "        \"BestParams\": study_lstm_reg.best_params,\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"TCN Reg (ranking)\",\n",
    "        \"Objective\": \"Sharpe\",\n",
    "        \"BestValObj\": -study_tcn_reg.best_value,\n",
    "        \"BestParams\": study_tcn_reg.best_params,\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"LSTM Classifier\",\n",
    "        \"Objective\": \"log-loss\",\n",
    "        \"BestValObj\": study_lstm_cls.best_value,  # lower is better\n",
    "        \"BestParams\": study_lstm_cls.best_params,\n",
    "    },\n",
    "]\n",
    "\n",
    "training_df = pd.DataFrame(train_rows)\n",
    "training_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
