{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8475d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05_sp500_cs_tree_robustness.ipynb\n",
    "# Robustness of cross-sectional SP500 tree vs momentum across multiple test windows\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "import optuna\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-darkgrid\")\n",
    "\n",
    "def sharpe_ratio_np(returns, freq: int = 252) -> float:\n",
    "    \"\"\"Simple annualized Sharpe on a 1D array of daily returns.\"\"\"\n",
    "    r = np.asarray(returns, dtype=float)\n",
    "    if r.size == 0 or np.isclose(r.std(), 0.0):\n",
    "        return 0.0\n",
    "    return np.sqrt(freq) * r.mean() / r.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e9c09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = os.path.abspath(\"..\")\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.data_loading_cross import load_sp500_adj_close\n",
    "from src.signals_cross import (\n",
    "    make_cross_sectional_signals,\n",
    "    build_cross_sectional_matrix,\n",
    "    CROSS_FEATURES,\n",
    ")\n",
    "\n",
    "from src.backtest import (\n",
    "    equity_curve_from_returns,\n",
    "    cagr,\n",
    "    annualized_vol,\n",
    "    sharpe_ratio,\n",
    "    max_drawdown,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a8a167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Global transaction cost setting ---\n",
    "# round-trip cost as a fraction of notional per 21-day \"trade\"\n",
    "# 0.0005 = 5 bps, 0.001 = 10 bps, etc.\n",
    "COST_BPS = 0.001  # tweak this to whatever you want to assume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b843fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SP500 panel as long as we can reasonably go\n",
    "# (set force_download=True the first time if needed)\n",
    "prices = load_sp500_adj_close(start=\"2000-01-01\")\n",
    "\n",
    "prices.info()\n",
    "print(\"Price panel shape:\", prices.shape)\n",
    "print(\"Date range:\", prices.index.min(), \"->\", prices.index.max())\n",
    "print(\"Number of tickers:\", len(prices.columns))\n",
    "\n",
    "lookahead = 21  # ~1 month forward return\n",
    "\n",
    "signals_df = make_cross_sectional_signals(prices, lookahead=lookahead)\n",
    "\n",
    "print(\"Signals shape:\", signals_df.shape)\n",
    "print(\"Columns:\", signals_df.columns.tolist())\n",
    "\n",
    "dates_all = signals_df.index.get_level_values(\"date\")\n",
    "tickers_all = signals_df.index.get_level_values(\"ticker\")\n",
    "\n",
    "print(\"Signals date range:\", dates_all.min(), \"->\", dates_all.max())\n",
    "print(\"Unique tickers in signals:\", len(np.unique(tickers_all)))\n",
    "\n",
    "# Build big (X, y, dates, tickers) matrix\n",
    "X, y, dates, tickers = build_cross_sectional_matrix(signals_df)\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "print(\"Feature names:\", CROSS_FEATURES)\n",
    "print(\"Min/max date:\", dates.min(), \"->\", dates.max())\n",
    "print(\"Num unique tickers:\", np.unique(tickers).size)\n",
    "\n",
    "# Quick sanity check on forward-return distribution\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(y, bins=100)\n",
    "plt.title(f\"Distribution of {lookahead}-day forward returns\")\n",
    "plt.xlabel(\"Forward return\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e854cc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "symbols_path = Path(PROJECT_ROOT) / \"data\" / \"sp500_symbols.csv\"\n",
    "symbols_df = pd.read_csv(symbols_path)\n",
    "\n",
    "if \"sector\" in symbols_df.columns:\n",
    "    sector_map = symbols_df.set_index(\"symbol\")[\"sector\"].to_dict()\n",
    "\n",
    "    # signals_df has MultiIndex (date, ticker)\n",
    "    signals_df[\"sector\"] = (\n",
    "        signals_df.index.get_level_values(\"ticker\")\n",
    "        .map(sector_map)\n",
    "        .fillna(\"ALL\")\n",
    "    )\n",
    "    print(\"Added sector column to signals_df.\")\n",
    "else:\n",
    "    sector_map = None\n",
    "    print(\n",
    "        \"Warning: sp500_symbols.csv has no 'sector' column – \"\n",
    "        \"sector-neutral experiments will be skipped.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcb825f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_momentum_cs(\n",
    "    group: pd.DataFrame,\n",
    "    q: float = 0.1,\n",
    "    horizon: int = 21,\n",
    "    cost_bps: float = 0.0,\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Cross-sectional momentum for a single date.\n",
    "\n",
    "    group: rows for one date, many tickers.\n",
    "    q: top/bottom quantile, e.g. 0.1 for deciles.\n",
    "    horizon: forward horizon used for the target (e.g. 21 days).\n",
    "    cost_bps: round-trip cost per 21-day position.\n",
    "    \"\"\"\n",
    "    n = len(group)\n",
    "    if n < 10:\n",
    "        return pd.Series({\"eqw\": 0.0, \"long\": 0.0, \"long_short\": 0.0})\n",
    "\n",
    "    # equal-weight all stocks -> \"index\" (21-day return, frictionless)\n",
    "    eqw_ret_21 = group[\"target_fwd_21\"].mean()\n",
    "\n",
    "    # sort by past 21d return (classical cross-sectional momentum)\n",
    "    g_sorted = group.sort_values(\"ret_21\")\n",
    "    k = max(1, int(n * q))\n",
    "\n",
    "    bottom = g_sorted.iloc[:k]\n",
    "    top    = g_sorted.iloc[-k:]\n",
    "\n",
    "    long_ret_21  = top[\"target_fwd_21\"].mean()\n",
    "    short_ret_21 = bottom[\"target_fwd_21\"].mean()\n",
    "    long_short_21 = long_ret_21 - short_ret_21\n",
    "\n",
    "    # Apply transaction costs on 21-day horizon\n",
    "    if cost_bps > 0.0:\n",
    "        long_ret_21   = (1.0 + long_ret_21) * (1.0 - cost_bps) - 1.0\n",
    "        long_short_21 = (1.0 + long_short_21) * (1.0 - 2.0 * cost_bps) - 1.0\n",
    "\n",
    "    # convert to daily\n",
    "    def to_daily(R):\n",
    "        return (1.0 + R) ** (1.0 / horizon) - 1.0\n",
    "\n",
    "    eqw_ret_daily    = to_daily(eqw_ret_21)\n",
    "    long_ret_daily   = to_daily(long_ret_21)\n",
    "    long_short_daily = to_daily(long_short_21)\n",
    "\n",
    "    return pd.Series(\n",
    "        {\n",
    "            \"eqw\": eqw_ret_daily,\n",
    "            \"long\": long_ret_daily,\n",
    "            \"long_short\": long_short_daily,\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "def compute_cs_daily_returns(\n",
    "    df: pd.DataFrame,\n",
    "    q: float = 0.1,\n",
    "    horizon: int = 21,\n",
    "    cost_bps: float = 0.0,\n",
    "):\n",
    "    \"\"\"\n",
    "    df: index (date, symbol), columns: y_true, y_pred (21d fwd returns + predictions)\n",
    "    Returns three Series of *daily-equivalent* returns:\n",
    "        eqw, long-only (top q), long-short (top q minus bottom q)\n",
    "\n",
    "    cost_bps:\n",
    "        round-trip transaction cost per 21-day holding period as fraction\n",
    "        e.g. 0.0005 = 5 bps, 0.001 = 10 bps.\n",
    "        Applied once for a long-only position and twice for a long-short position.\n",
    "    \"\"\"\n",
    "\n",
    "    def _per_date(group: pd.DataFrame) -> pd.Series:\n",
    "        n = len(group)\n",
    "        if n < 10:\n",
    "            return pd.Series({\"eqw\": 0.0, \"long\": 0.0, \"long_short\": 0.0})\n",
    "\n",
    "        # Equal-weight all stocks -> benchmark (frictionless)\n",
    "        eqw_ret_21 = group[\"y_true\"].mean()\n",
    "\n",
    "        # Sort by predicted forward return\n",
    "        g_sorted = group.sort_values(\"y_pred\")\n",
    "        k = max(1, int(n * q))\n",
    "\n",
    "        bottom = g_sorted.iloc[:k]     # worst predicted\n",
    "        top    = g_sorted.iloc[-k:]    # best predicted\n",
    "\n",
    "        long_ret_21  = top[\"y_true\"].mean()\n",
    "        short_ret_21 = bottom[\"y_true\"].mean()\n",
    "\n",
    "        long_short_21 = long_ret_21 - short_ret_21\n",
    "\n",
    "        # apply transaction costs\n",
    "        if cost_bps > 0.0:\n",
    "            long_ret_21   = (1.0 + long_ret_21) * (1.0 - cost_bps) - 1.0\n",
    "            long_short_21 = (1.0 + long_short_21) * (1.0 - 2.0 * cost_bps) - 1.0\n",
    "\n",
    "        def to_daily(R):\n",
    "            return (1.0 + R) ** (1.0 / horizon) - 1.0\n",
    "\n",
    "        eqw_daily        = to_daily(eqw_ret_21)\n",
    "        long_daily       = to_daily(long_ret_21)\n",
    "        long_short_daily = to_daily(long_short_21)\n",
    "\n",
    "        return pd.Series(\n",
    "            {\"eqw\": eqw_daily, \"long\": long_daily, \"long_short\": long_short_daily}\n",
    "        )\n",
    "\n",
    "    daily = df.groupby(\"date\").apply(_per_date)\n",
    "\n",
    "    eqw = daily[\"eqw\"].astype(float)\n",
    "    long = daily[\"long\"].astype(float)\n",
    "    long_short = daily[\"long_short\"].astype(float)\n",
    "\n",
    "    return eqw, long, long_short\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63770b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cs_daily_returns_gated(\n",
    "    df: pd.DataFrame,\n",
    "    q: float = 0.1,\n",
    "    horizon: int = 21,\n",
    "    cost_bps: float = 0.0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Like compute_cs_daily_returns, but:\n",
    "    - uses model predictions to decide whether to trade at all,\n",
    "    - only applies costs on days where we actually trade.\n",
    "\n",
    "    df: index (date, symbol), columns: y_true, y_pred\n",
    "    \"\"\"\n",
    "\n",
    "    def _per_date(group: pd.DataFrame) -> pd.Series:\n",
    "        n = len(group)\n",
    "        if n < 10:\n",
    "            return pd.Series({\"eqw\": 0.0, \"long\": 0.0, \"long_short\": 0.0})\n",
    "\n",
    "        # Benchmark: equal-weight all stocks (no costs)\n",
    "        eqw_ret_21 = group[\"y_true\"].mean()\n",
    "\n",
    "        # Rank by predicted forward return\n",
    "        g_sorted = group.sort_values(\"y_pred\")\n",
    "        k = max(1, int(n * q))\n",
    "\n",
    "        bottom = g_sorted.iloc[:k]\n",
    "        top    = g_sorted.iloc[-k:]\n",
    "\n",
    "        # --- True 21d returns (what actually happens) ---\n",
    "        long_true_21  = top[\"y_true\"].mean()\n",
    "        short_true_21 = bottom[\"y_true\"].mean()\n",
    "        long_short_true_21 = long_true_21 - short_true_21\n",
    "\n",
    "        # --- Predicted 21d returns (model view) ---\n",
    "        long_pred_21  = top[\"y_pred\"].mean()\n",
    "        short_pred_21 = bottom[\"y_pred\"].mean()\n",
    "        long_short_pred_21 = long_pred_21 - short_pred_21\n",
    "\n",
    "        # ---- Decision: do we trade? ----\n",
    "        # Long-only: require predicted edge > cost\n",
    "        trade_long = long_pred_21 > cost_bps\n",
    "\n",
    "        # Long-short: require predicted spread > 2 * cost\n",
    "        trade_ls   = long_short_pred_21 > 2.0 * cost_bps\n",
    "\n",
    "        # Start from \"no trade\"\n",
    "        long_ret_21      = 0.0\n",
    "        long_short_21    = 0.0\n",
    "\n",
    "        if trade_long:\n",
    "            long_ret_21 = long_true_21\n",
    "\n",
    "        if trade_ls:\n",
    "            long_short_21 = long_short_true_21\n",
    "\n",
    "        # ---- Apply costs only if we actually trade ----\n",
    "        if cost_bps > 0.0 and trade_long:\n",
    "            long_ret_21 = (1.0 + long_ret_21) * (1.0 - cost_bps) - 1.0\n",
    "\n",
    "        if cost_bps > 0.0 and trade_ls:\n",
    "            long_short_21 = (1.0 + long_short_21) * (1.0 - 2.0 * cost_bps) - 1.0\n",
    "\n",
    "        # Convert 21-day returns to daily-equivalent\n",
    "        def to_daily(R):\n",
    "            return (1.0 + R) ** (1.0 / horizon) - 1.0\n",
    "\n",
    "        eqw_daily        = to_daily(eqw_ret_21)\n",
    "        long_daily       = to_daily(long_ret_21)\n",
    "        long_short_daily = to_daily(long_short_21)\n",
    "\n",
    "        return pd.Series(\n",
    "            {\"eqw\": eqw_daily, \"long\": long_daily, \"long_short\": long_short_daily}\n",
    "        )\n",
    "\n",
    "    daily = df.groupby(\"date\").apply(_per_date)\n",
    "\n",
    "    eqw = daily[\"eqw\"].astype(float)\n",
    "    long = daily[\"long\"].astype(float)\n",
    "    long_short = daily[\"long_short\"].astype(float)\n",
    "\n",
    "    return eqw, long, long_short\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35f1f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_momentum_cs_sector_neutral(\n",
    "    group: pd.DataFrame,\n",
    "    q: float = 0.1,\n",
    "    horizon: int = 21,\n",
    "    cost_bps: float = 0.0,\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Sector-neutral cross-sectional momentum for a single date.\n",
    "\n",
    "    group: rows for one date, many tickers, with columns:\n",
    "        target_fwd_21, ret_21, sector\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(group)\n",
    "    if n < 10 or \"sector\" not in group.columns:\n",
    "        # Fall back to non-sector version\n",
    "        return daily_momentum_cs(group, q=q, horizon=horizon, cost_bps=cost_bps)\n",
    "\n",
    "    # Benchmark (frictionless)\n",
    "    eqw_ret_21 = group[\"target_fwd_21\"].mean()\n",
    "\n",
    "    sector_long = []\n",
    "    sector_short = []\n",
    "\n",
    "    for sec, g_sec in group.groupby(\"sector\"):\n",
    "        m = len(g_sec)\n",
    "        if m < 5:\n",
    "            continue\n",
    "\n",
    "        g_sorted = g_sec.sort_values(\"ret_21\")\n",
    "        k = max(1, int(m * q))\n",
    "\n",
    "        bottom = g_sorted.iloc[:k]\n",
    "        top    = g_sorted.iloc[-k:]\n",
    "\n",
    "        sector_long.append(top[\"target_fwd_21\"].mean())\n",
    "        sector_short.append(bottom[\"target_fwd_21\"].mean())\n",
    "\n",
    "    if not sector_long:\n",
    "        return pd.Series({\"eqw\": 0.0, \"long\": 0.0, \"long_short\": 0.0})\n",
    "\n",
    "    long_ret_21  = float(np.mean(sector_long))\n",
    "    short_ret_21 = float(np.mean(sector_short))\n",
    "    long_short_21 = long_ret_21 - short_ret_21\n",
    "\n",
    "    if cost_bps > 0.0:\n",
    "        long_ret_21   = (1.0 + long_ret_21) * (1.0 - cost_bps) - 1.0\n",
    "        long_short_21 = (1.0 + long_short_21) * (1.0 - 2.0 * cost_bps) - 1.0\n",
    "\n",
    "    def to_daily(R):\n",
    "        return (1.0 + R) ** (1.0 / horizon) - 1.0\n",
    "\n",
    "    eqw_daily    = to_daily(eqw_ret_21)\n",
    "    long_daily   = to_daily(long_ret_21)\n",
    "    ls_daily     = to_daily(long_short_21)\n",
    "\n",
    "    return pd.Series({\"eqw\": eqw_daily, \"long\": long_daily, \"long_short\": ls_daily})\n",
    "\n",
    "\n",
    "def compute_cs_daily_returns_sector_neutral(\n",
    "    df: pd.DataFrame,\n",
    "    q: float = 0.1,\n",
    "    horizon: int = 21,\n",
    "    cost_bps: float = 0.0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Sector-neutral version of compute_cs_daily_returns.\n",
    "    df: index (date, symbol), columns: y_true, y_pred, sector.\n",
    "    \"\"\"\n",
    "\n",
    "    if \"sector\" not in df.columns:\n",
    "        # Graceful fallback\n",
    "        return compute_cs_daily_returns(df, q=q, horizon=horizon, cost_bps=cost_bps)\n",
    "\n",
    "    def _per_date(group: pd.DataFrame) -> pd.Series:\n",
    "        n = len(group)\n",
    "        if n < 10:\n",
    "            return pd.Series({\"eqw\": 0.0, \"long\": 0.0, \"long_short\": 0.0})\n",
    "\n",
    "        eqw_ret_21 = group[\"y_true\"].mean()\n",
    "\n",
    "        sector_long = []\n",
    "        sector_short = []\n",
    "\n",
    "        for sec, g_sec in group.groupby(\"sector\"):\n",
    "            m = len(g_sec)\n",
    "            if m < 5:\n",
    "                continue\n",
    "\n",
    "            g_sorted = g_sec.sort_values(\"y_pred\")\n",
    "            k = max(1, int(m * q))\n",
    "\n",
    "            bottom = g_sorted.iloc[:k]\n",
    "            top    = g_sorted.iloc[-k:]\n",
    "\n",
    "            sector_long.append(top[\"y_true\"].mean())\n",
    "            sector_short.append(bottom[\"y_true\"].mean())\n",
    "\n",
    "        if not sector_long:\n",
    "            return pd.Series({\"eqw\": 0.0, \"long\": 0.0, \"long_short\": 0.0})\n",
    "\n",
    "        long_ret_21  = float(np.mean(sector_long))\n",
    "        short_ret_21 = float(np.mean(sector_short))\n",
    "        long_short_21 = long_ret_21 - short_ret_21\n",
    "\n",
    "        if cost_bps > 0.0:\n",
    "            long_ret_21   = (1.0 + long_ret_21) * (1.0 - cost_bps) - 1.0\n",
    "            long_short_21 = (1.0 + long_short_21) * (1.0 - 2.0 * cost_bps) - 1.0\n",
    "\n",
    "        def to_daily(R):\n",
    "            return (1.0 + R) ** (1.0 / horizon) - 1.0\n",
    "\n",
    "        eqw_daily    = to_daily(eqw_ret_21)\n",
    "        long_daily   = to_daily(long_ret_21)\n",
    "        ls_daily     = to_daily(long_short_21)\n",
    "\n",
    "        return pd.Series({\"eqw\": eqw_daily, \"long\": long_daily, \"long_short\": ls_daily})\n",
    "\n",
    "    daily = df.groupby(\"date\").apply(_per_date)\n",
    "    eqw = daily[\"eqw\"].astype(float)\n",
    "    long = daily[\"long\"].astype(float)\n",
    "    long_short = daily[\"long_short\"].astype(float)\n",
    "    return eqw, long, long_short\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e89bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cs_window(\n",
    "    test_start: str,\n",
    "    test_end: str,\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    dates: pd.Series,\n",
    "    tickers: np.ndarray,\n",
    "    signals_df: pd.DataFrame,\n",
    "    n_trials: int = 10,\n",
    "    q_mom: float = 0.1,\n",
    "    cost_bps: float = COST_BPS,\n",
    "    random_state: int = 42,\n",
    "):\n",
    "    \"\"\"\n",
    "    Run the full pipeline for a single test window:\n",
    "    - Train/val on data *before* test_start\n",
    "    - Tune tree + XGB + q on validation long-short Sharpe (net of costs)\n",
    "    - Evaluate momentum, tree, and XGB on [test_start, test_end]\n",
    "    \"\"\"\n",
    "    test_start = pd.Timestamp(test_start)\n",
    "    test_end   = pd.Timestamp(test_end)\n",
    "\n",
    "    # Masks for this window\n",
    "    test_mask = (dates >= test_start) & (dates <= test_end)\n",
    "    hist_mask = dates < test_start\n",
    "\n",
    "    if test_mask.sum() == 0 or hist_mask.sum() < 1000:\n",
    "        print(f\"Skipping window {test_start.date()}–{test_end.date()} (not enough data).\")\n",
    "        return None\n",
    "\n",
    "    # 70/30 split of *history* into train/val\n",
    "    hist_dates = np.array(sorted(dates[hist_mask].unique()))\n",
    "    train_end_local = hist_dates[int(len(hist_dates) * 0.7)]\n",
    "\n",
    "    train_mask = (dates <= train_end_local)\n",
    "    val_mask   = (dates > train_end_local) & (dates < test_start)\n",
    "\n",
    "    X_train, y_train = X[train_mask], y[train_mask]\n",
    "    X_val,   y_val   = X[val_mask],   y[val_mask]\n",
    "    X_test,  y_test  = X[test_mask],  y[test_mask]\n",
    "\n",
    "    dates_val_local    = dates[val_mask]\n",
    "    dates_test_local   = dates[test_mask]\n",
    "    tickers_val_local  = tickers[val_mask]\n",
    "    tickers_test_local = tickers[test_mask]\n",
    "\n",
    "    print(\n",
    "        f\"Window {test_start.date()}–{test_end.date()} | \"\n",
    "        f\"train={len(y_train)}, val={len(y_val)}, test={len(y_test)}\"\n",
    "    )\n",
    "\n",
    "    # -------------------------\n",
    "    # Optuna objectives\n",
    "    # -------------------------\n",
    "    def objective_tree_cs(trial):\n",
    "        max_depth        = trial.suggest_int(\"max_depth\", 2, 8)\n",
    "        learning_rate    = trial.suggest_float(\"learning_rate\", 0.01, 0.2, log=True)\n",
    "        max_iter         = trial.suggest_int(\"max_iter\", 100, 500)\n",
    "        min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 20, 200)\n",
    "        q                = trial.suggest_float(\"q\", 0.05, 0.3)  # top/bottom 5–30%\n",
    "\n",
    "        model = HistGradientBoostingRegressor(\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            max_iter=max_iter,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_val = model.predict(X_val)\n",
    "\n",
    "        df_val = (\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"date\":   dates_val_local,\n",
    "                    \"symbol\": tickers_val_local,\n",
    "                    \"y_true\": y_val,\n",
    "                    \"y_pred\": y_pred_val,\n",
    "                }\n",
    "            )\n",
    "            .set_index([\"date\", \"symbol\"])\n",
    "            .sort_index()\n",
    "        )\n",
    "\n",
    "        # long-short (NET of costs)\n",
    "        _, _, long_short_val = compute_cs_daily_returns(\n",
    "            df_val,\n",
    "            q=q,\n",
    "            horizon=lookahead,\n",
    "            cost_bps=cost_bps,\n",
    "        )\n",
    "\n",
    "        ret_series = long_short_val.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "        if len(ret_series) < 20:\n",
    "            return 0.0\n",
    "\n",
    "        return -sharpe_ratio_np(ret_series.values)\n",
    "\n",
    "    def objective_xgb_cs(trial):\n",
    "        # Reasonable XGB hyperparameter ranges\n",
    "        max_depth        = trial.suggest_int(\"max_depth\", 2, 8)\n",
    "        learning_rate    = trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True)\n",
    "        n_estimators     = trial.suggest_int(\"n_estimators\", 100, 600)\n",
    "        subsample        = trial.suggest_float(\"subsample\", 0.6, 1.0)\n",
    "        colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.6, 1.0)\n",
    "        min_child_weight = trial.suggest_float(\"min_child_weight\", 1.0, 20.0)\n",
    "        q                = trial.suggest_float(\"q\", 0.05, 0.3)\n",
    "\n",
    "        model = XGBRegressor(\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            n_estimators=n_estimators,\n",
    "            subsample=subsample,\n",
    "            colsample_bytree=colsample_bytree,\n",
    "            min_child_weight=min_child_weight,\n",
    "            objective=\"reg:squarederror\",\n",
    "            tree_method=\"hist\",\n",
    "            n_jobs=-1,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_val = model.predict(X_val)\n",
    "        df_val = (\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"date\":   dates_val_local,\n",
    "                    \"symbol\": tickers_val_local,\n",
    "                    \"y_true\": y_val,\n",
    "                    \"y_pred\": y_pred_val,\n",
    "                }\n",
    "            )\n",
    "            .set_index([\"date\", \"symbol\"])\n",
    "            .sort_index()\n",
    "        )\n",
    "\n",
    "        _, _, long_short_val = compute_cs_daily_returns(\n",
    "            df_val,\n",
    "            q=q,\n",
    "            horizon=lookahead,\n",
    "            cost_bps=cost_bps,\n",
    "        )\n",
    "\n",
    "        ret_series = long_short_val.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "        if len(ret_series) < 20:\n",
    "            return 0.0\n",
    "\n",
    "        return -sharpe_ratio_np(ret_series.values)\n",
    "\n",
    "    # --- tune tree ---\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective_tree_cs, n_trials=n_trials)\n",
    "    print(\"  Tree best params:\", study.best_params)\n",
    "    print(\"  Tree best val -Sharpe:\", study.best_value)\n",
    "\n",
    "    best_params = study.best_params.copy()\n",
    "    q_best = best_params.pop(\"q\")\n",
    "\n",
    "    # --- tune XGB ---\n",
    "    study_xgb = optuna.create_study(direction=\"minimize\")\n",
    "    study_xgb.optimize(objective_xgb_cs, n_trials=n_trials)\n",
    "    print(\"  XGB best params:\", study_xgb.best_params)\n",
    "    print(\"  XGB best val -Sharpe:\", study_xgb.best_value)\n",
    "\n",
    "    best_params_xgb = study_xgb.best_params.copy()\n",
    "    q_best_xgb = best_params_xgb.pop(\"q\")\n",
    "\n",
    "    # Train on all history (train+val) before test_start\n",
    "    hist_mask_full = dates < test_start\n",
    "    X_hist, y_hist = X[hist_mask_full], y[hist_mask_full]\n",
    "\n",
    "    tree_best = HistGradientBoostingRegressor(\n",
    "        **best_params,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "    tree_best.fit(X_hist, y_hist)\n",
    "\n",
    "    xgb_best = XGBRegressor(\n",
    "        **best_params_xgb,\n",
    "        objective=\"reg:squarederror\",\n",
    "        tree_method=\"hist\",\n",
    "        n_jobs=-1,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "    xgb_best.fit(X_hist, y_hist)\n",
    "\n",
    "    # -------------------------\n",
    "    # 1) Momentum baseline on this test window (NET)\n",
    "    # -------------------------\n",
    "    idx_dates = signals_df.index.get_level_values(\"date\")\n",
    "    signals_test = signals_df.loc[\n",
    "        (idx_dates >= test_start) & (idx_dates <= test_end)\n",
    "    ].copy()\n",
    "\n",
    "    daily_mom = signals_test.groupby(\"date\").apply(\n",
    "        daily_momentum_cs,\n",
    "        q=q_mom,\n",
    "        horizon=lookahead,\n",
    "        cost_bps=cost_bps,\n",
    "    )\n",
    "\n",
    "    eqw_returns   = daily_mom[\"eqw\"].astype(float)\n",
    "    momL_returns  = daily_mom[\"long\"].astype(float)\n",
    "    momLS_returns = daily_mom[\"long_short\"].astype(float)\n",
    "\n",
    "    # -------------------------\n",
    "    # 2) Tree strategy on this test window (NET)\n",
    "    # -------------------------\n",
    "    y_pred_test = tree_best.predict(X_test)\n",
    "\n",
    "    df_test = (\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"date\":   dates_test_local,\n",
    "                \"symbol\": tickers_test_local,\n",
    "                \"y_true\": y_test,\n",
    "                \"y_pred\": y_pred_test,\n",
    "            }\n",
    "        )\n",
    "        .set_index([\"date\", \"symbol\"])\n",
    "        .sort_index()\n",
    "    )\n",
    "\n",
    "    _, treeL_returns, treeLS_returns = compute_cs_daily_returns(\n",
    "        df_test, q=q_best, horizon=lookahead, cost_bps=cost_bps\n",
    "    )\n",
    "\n",
    "    # -------------------------\n",
    "    # 3) XGB strategy on this test window (NET)\n",
    "    # -------------------------\n",
    "    y_pred_test_xgb = xgb_best.predict(X_test)\n",
    "    df_test_xgb = (\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"date\":   dates_test_local,\n",
    "                \"symbol\": tickers_test_local,\n",
    "                \"y_true\": y_test,\n",
    "                \"y_pred\": y_pred_test_xgb,\n",
    "            }\n",
    "        )\n",
    "        .set_index([\"date\", \"symbol\"])\n",
    "        .sort_index()\n",
    "    )\n",
    "\n",
    "    _, xgbL_returns, xgbLS_returns = compute_cs_daily_returns(\n",
    "        df_test_xgb,\n",
    "        q=q_best_xgb,\n",
    "        horizon=lookahead,\n",
    "        cost_bps=cost_bps,\n",
    "    )\n",
    "\n",
    "    # Equity curves\n",
    "    eqw_eq     = equity_curve_from_returns(eqw_returns)\n",
    "    momL_eq    = equity_curve_from_returns(momL_returns)\n",
    "    momLS_eq   = equity_curve_from_returns(momLS_returns)\n",
    "    treeL_eq   = equity_curve_from_returns(treeL_returns)\n",
    "    treeLS_eq  = equity_curve_from_returns(treeLS_returns)\n",
    "    xgbL_eq    = equity_curve_from_returns(xgbL_returns)\n",
    "    xgbLS_eq   = equity_curve_from_returns(xgbLS_returns)\n",
    "\n",
    "    # ---------- Sector-neutral versions (if sector_map is available) ----------\n",
    "    if \"sector_map\" in globals() and sector_map is not None:\n",
    "        df_test_tree_sn = df_test.copy()\n",
    "        df_test_tree_sn[\"sector\"] = (\n",
    "            df_test_tree_sn.index.get_level_values(\"symbol\")\n",
    "            .map(sector_map)\n",
    "            .fillna(\"ALL\")\n",
    "        )\n",
    "        _, treeL_sn_returns, treeLS_sn_returns = compute_cs_daily_returns_sector_neutral(\n",
    "            df_test_tree_sn,\n",
    "            q=q_best,\n",
    "            horizon=lookahead,\n",
    "            cost_bps=cost_bps,\n",
    "        )\n",
    "\n",
    "        df_test_xgb_sn = df_test_xgb.copy()\n",
    "        df_test_xgb_sn[\"sector\"] = (\n",
    "            df_test_xgb_sn.index.get_level_values(\"symbol\")\n",
    "            .map(sector_map)\n",
    "            .fillna(\"ALL\")\n",
    "        )\n",
    "        _, xgbL_sn_returns, xgbLS_sn_returns = compute_cs_daily_returns_sector_neutral(\n",
    "            df_test_xgb_sn,\n",
    "            q=q_best_xgb,\n",
    "            horizon=lookahead,\n",
    "            cost_bps=cost_bps,\n",
    "        )\n",
    "    else:\n",
    "        # fallback: reuse non-sector-neutral returns\n",
    "        treeL_sn_returns  = treeL_returns\n",
    "        treeLS_sn_returns = treeLS_returns\n",
    "        xgbL_sn_returns   = xgbL_returns\n",
    "        xgbLS_sn_returns  = xgbLS_returns\n",
    "\n",
    "    # -------------------------\n",
    "    # Metrics dict for this window\n",
    "    # -------------------------\n",
    "    metrics = {\n",
    "        \"test_start\": test_start.date(),\n",
    "        \"test_end\":   test_end.date(),\n",
    "\n",
    "        \"momL_cagr\":    cagr(momL_eq),\n",
    "        \"momL_sharpe\":  sharpe_ratio(momL_returns),\n",
    "        \"momL_max_dd\":  max_drawdown(momL_eq),\n",
    "\n",
    "        \"treeL_cagr\":   cagr(treeL_eq),\n",
    "        \"treeL_sharpe\": sharpe_ratio(treeL_returns),\n",
    "        \"treeL_max_dd\": max_drawdown(treeL_eq),\n",
    "\n",
    "        \"momLS_cagr\":   cagr(momLS_eq),\n",
    "        \"momLS_sharpe\": sharpe_ratio(momLS_returns),\n",
    "        \"momLS_max_dd\": max_drawdown(momLS_eq),\n",
    "\n",
    "        \"treeLS_cagr\":   cagr(treeLS_eq),\n",
    "        \"treeLS_sharpe\": sharpe_ratio(treeLS_returns),\n",
    "        \"treeLS_max_dd\": max_drawdown(treeLS_eq),\n",
    "\n",
    "        \"xgbL_cagr\":    cagr(xgbL_eq),\n",
    "        \"xgbL_sharpe\":  sharpe_ratio(xgbL_returns),\n",
    "        \"xgbLS_cagr\":   cagr(xgbLS_eq),\n",
    "        \"xgbLS_sharpe\": sharpe_ratio(xgbLS_returns),\n",
    "\n",
    "        \"treeL_sn_sharpe\":  sharpe_ratio(treeL_sn_returns),\n",
    "        \"treeLS_sn_sharpe\": sharpe_ratio(treeLS_sn_returns),\n",
    "        \"xgbL_sn_sharpe\":   sharpe_ratio(xgbL_sn_returns),\n",
    "        \"xgbLS_sn_sharpe\":  sharpe_ratio(xgbLS_sn_returns),\n",
    "    }\n",
    "\n",
    "    # quick plot for this window\n",
    "    plt.figure(figsize=(9, 4))\n",
    "    momL_eq.plot(label=\"Momentum long-only (net)\")\n",
    "    treeL_eq.plot(label=\"Tree long-only (net)\")\n",
    "    xgbL_eq.plot(label=\"XGB long-only (net)\", linestyle=\":\")\n",
    "    plt.legend()\n",
    "    plt.title(f\"Long-only (net of costs): {test_start.date()}–{test_end.date()}\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(9, 4))\n",
    "    momLS_eq.plot(label=\"Momentum long-short (net)\")\n",
    "    treeLS_eq.plot(label=\"Tree long-short (net)\")\n",
    "    xgbLS_eq.plot(label=\"XGB long-short (net)\", linestyle=\":\")\n",
    "    plt.legend()\n",
    "    plt.title(f\"Long-short (net of costs): {test_start.date()}–{test_end.date()}\")\n",
    "    plt.show()\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933a6b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_windows = [\n",
    "    (\"2005-01-01\", \"2009-12-31\"),\n",
    "    (\"2010-01-01\", \"2014-12-31\"),\n",
    "    (\"2015-01-01\", \"2019-12-31\"),\n",
    "    (\"2020-01-01\", \"2024-12-31\"),\n",
    "]\n",
    "\n",
    "results = []\n",
    "for start, end in test_windows:\n",
    "    print(\"=\" * 80)\n",
    "    m = run_cs_window(\n",
    "        start,\n",
    "        end,\n",
    "        X=X,\n",
    "        y=y,\n",
    "        dates=dates,\n",
    "        tickers=tickers,\n",
    "        signals_df=signals_df,\n",
    "        n_trials=10,\n",
    "        q_mom=0.1,\n",
    "    )\n",
    "    if m is not None:\n",
    "        results.append(m)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3b63bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# Aggregate results across windows and build summary tables / plots\n",
    "# --------------------------------------------------------------------\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df\n",
    "\n",
    "summary_cols = [\n",
    "    \"test_start\", \"test_end\",\n",
    "    \"momL_sharpe\", \"treeL_sharpe\", \"xgbL_sharpe\",\n",
    "    \"momLS_sharpe\", \"treeLS_sharpe\", \"xgbLS_sharpe\",\n",
    "    \"treeL_sn_sharpe\", \"xgbL_sn_sharpe\",\n",
    "    \"treeLS_sn_sharpe\", \"xgbLS_sn_sharpe\",\n",
    "]\n",
    "\n",
    "summary = results_df[summary_cols].copy()\n",
    "summary\n",
    "\n",
    "# Differences vs momentum\n",
    "summary[\"treeL_minus_momL\"]   = summary[\"treeL_sharpe\"]  - summary[\"momL_sharpe\"]\n",
    "summary[\"treeLS_minus_momLS\"] = summary[\"treeLS_sharpe\"] - summary[\"momLS_sharpe\"]\n",
    "summary[\"xgbL_minus_momL\"]    = summary[\"xgbL_sharpe\"]   - summary[\"momL_sharpe\"]\n",
    "summary[\"xgbLS_minus_momLS\"]  = summary[\"xgbLS_sharpe\"]  - summary[\"momLS_sharpe\"]\n",
    "\n",
    "summary\n",
    "\n",
    "# Nice labels for windows\n",
    "window_labels = (\n",
    "    results_df[\"test_start\"].astype(str)\n",
    "    + \"–\"\n",
    "    + results_df[\"test_end\"].astype(str)\n",
    ")\n",
    "x = np.arange(len(results_df))\n",
    "width = 0.25  # 3 bars per window\n",
    "\n",
    "# --- Long-only Sharpe: momentum vs tree vs XGB ---\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.bar(x - width,   results_df[\"momL_sharpe\"],  width, label=\"Momentum long-only\")\n",
    "plt.bar(x,           results_df[\"treeL_sharpe\"], width, label=\"Tree long-only\")\n",
    "plt.bar(x + width,   results_df[\"xgbL_sharpe\"],  width, label=\"XGB long-only\")\n",
    "plt.xticks(x, window_labels, rotation=30, ha=\"right\")\n",
    "plt.ylabel(\"Sharpe\")\n",
    "plt.title(\"Long-only Sharpe by test window (net of costs)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Long-short Sharpe: momentum vs tree vs XGB ---\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.bar(x - width,   results_df[\"momLS_sharpe\"], width, label=\"Momentum long-short\")\n",
    "plt.bar(x,           results_df[\"treeLS_sharpe\"], width, label=\"Tree long-short\")\n",
    "plt.bar(x + width,   results_df[\"xgbLS_sharpe\"],  width, label=\"XGB long-short\")\n",
    "plt.xticks(x, window_labels, rotation=30, ha=\"right\")\n",
    "plt.ylabel(\"Sharpe\")\n",
    "plt.title(\"Long-short Sharpe by test window (net of costs)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Δ Sharpe vs momentum (long-only) ---\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.bar(x - width/2, summary[\"treeL_minus_momL\"], width, label=\"Tree - momentum\")\n",
    "plt.bar(x + width/2, summary[\"xgbL_minus_momL\"],  width, label=\"XGB - momentum\")\n",
    "plt.axhline(0, color=\"black\", linewidth=1)\n",
    "plt.xticks(x, window_labels, rotation=30, ha=\"right\")\n",
    "plt.ylabel(\"Δ Sharpe\")\n",
    "plt.title(\"Long-only: ML vs momentum (per window)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Δ Sharpe vs momentum (long-short) ---\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.bar(x - width/2, summary[\"treeLS_minus_momLS\"], width, label=\"Tree - momentum\")\n",
    "plt.bar(x + width/2, summary[\"xgbLS_minus_momLS\"],  width, label=\"XGB - momentum\")\n",
    "plt.axhline(0, color=\"black\", linewidth=1)\n",
    "plt.xticks(x, window_labels, rotation=30, ha=\"right\")\n",
    "plt.ylabel(\"Δ Sharpe\")\n",
    "plt.title(\"Long-short: ML vs momentum (per window)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Long-only scatter: momentum vs tree, momentum vs XGB ---\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(results_df[\"momL_sharpe\"], results_df[\"treeL_sharpe\"], label=\"Tree\")\n",
    "plt.scatter(results_df[\"momL_sharpe\"], results_df[\"xgbL_sharpe\"],  label=\"XGB\", marker=\"x\")\n",
    "lims = [\n",
    "    min(results_df[[\"momL_sharpe\", \"treeL_sharpe\", \"xgbL_sharpe\"]].min()) - 0.2,\n",
    "    max(results_df[[\"momL_sharpe\", \"treeL_sharpe\", \"xgbL_sharpe\"]].max()) + 0.2,\n",
    "]\n",
    "plt.plot(lims, lims, \"--\", color=\"gray\")  # y = x line\n",
    "for i, label in enumerate(window_labels):\n",
    "    plt.text(\n",
    "        results_df[\"momL_sharpe\"].iloc[i] + 0.02,\n",
    "        results_df[\"treeL_sharpe\"].iloc[i] + 0.02,\n",
    "        label,\n",
    "        fontsize=8,\n",
    "    )\n",
    "plt.xlim(lims)\n",
    "plt.ylim(lims)\n",
    "plt.xlabel(\"Momentum long-only Sharpe\")\n",
    "plt.ylabel(\"ML long-only Sharpe\")\n",
    "plt.title(\"Long-only: momentum vs ML across windows\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Long-short scatter: momentum vs tree, momentum vs XGB ---\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(results_df[\"momLS_sharpe\"], results_df[\"treeLS_sharpe\"], label=\"Tree\")\n",
    "plt.scatter(results_df[\"momLS_sharpe\"], results_df[\"xgbLS_sharpe\"],  label=\"XGB\", marker=\"x\")\n",
    "lims = [\n",
    "    min(results_df[[\"momLS_sharpe\", \"treeLS_sharpe\", \"xgbLS_sharpe\"]].min()) - 0.2,\n",
    "    max(results_df[[\"momLS_sharpe\", \"treeLS_sharpe\", \"xgbLS_sharpe\"]].max()) + 0.2,\n",
    "]\n",
    "plt.plot(lims, lims, \"--\", color=\"gray\")\n",
    "for i, label in enumerate(window_labels):\n",
    "    plt.text(\n",
    "        results_df[\"momLS_sharpe\"].iloc[i] + 0.02,\n",
    "        results_df[\"treeLS_sharpe\"].iloc[i] + 0.02,\n",
    "        label,\n",
    "        fontsize=8,\n",
    "    )\n",
    "plt.xlim(lims)\n",
    "plt.ylim(lims)\n",
    "plt.xlabel(\"Momentum long-short Sharpe\")\n",
    "plt.ylabel(\"ML long-short Sharpe\")\n",
    "plt.title(\"Long-short: momentum vs ML across windows\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2818bef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PAPER TRADING MODE, FOR RESEARCH PURPOSE ONLY: cross-sectional SP500 picks for \"tomorrow\" ===\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "TOP_N_LONG = 20   # how many longs to show\n",
    "TOP_N_SHORT = 20  # how many shorts to show\n",
    "\n",
    "# 1) Choose as-of date: last date where we have signals/targets\n",
    "as_of_date = dates.max()\n",
    "print(f\"As-of date for paper trading: {as_of_date.date()}\")\n",
    "\n",
    "# ----- build train / val sets using only history before as_of_date -----\n",
    "hist_mask = dates < as_of_date\n",
    "if hist_mask.sum() < 1000:\n",
    "    raise ValueError(\"Not enough history before as_of_date for a meaningful model.\")\n",
    "\n",
    "hist_dates = np.array(sorted(dates[hist_mask].unique()))\n",
    "train_end_live = hist_dates[int(len(hist_dates) * 0.7)]\n",
    "\n",
    "train_mask_live = (dates <= train_end_live)\n",
    "val_mask_live   = (dates > train_end_live) & (dates < as_of_date)\n",
    "\n",
    "X_train_live, y_train_live = X[train_mask_live], y[train_mask_live]\n",
    "X_val_live,   y_val_live   = X[val_mask_live],   y[val_mask_live]\n",
    "\n",
    "dates_val_live   = dates[val_mask_live]\n",
    "tickers_val_live = tickers[val_mask_live]\n",
    "\n",
    "print(\n",
    "    f\"Live setup | train={len(y_train_live)} samples \"\n",
    "    f\"val={len(y_val_live)} samples (all < {as_of_date.date()})\"\n",
    ")\n",
    "\n",
    "# 2) Optuna objective: tune tree hyperparams + q on long-short Sharpe (net of cost)\n",
    "def objective_tree_live(trial):\n",
    "    max_depth       = trial.suggest_int(\"max_depth\", 2, 8)\n",
    "    learning_rate   = trial.suggest_float(\"learning_rate\", 0.01, 0.2, log=True)\n",
    "    max_iter        = trial.suggest_int(\"max_iter\", 100, 500)\n",
    "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 20, 200)\n",
    "    q               = trial.suggest_float(\"q\", 0.05, 0.3)  # top/bottom 5–30%\n",
    "\n",
    "    model = HistGradientBoostingRegressor(\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        max_iter=max_iter,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=42,\n",
    "    )\n",
    "    model.fit(X_train_live, y_train_live)\n",
    "\n",
    "    y_pred_val = model.predict(X_val_live)\n",
    "\n",
    "    df_val_live = (\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"date\":   dates_val_live,\n",
    "                \"symbol\": tickers_val_live,\n",
    "                \"y_true\": y_val_live,\n",
    "                \"y_pred\": y_pred_val,\n",
    "            }\n",
    "        )\n",
    "        .set_index([\"date\", \"symbol\"])\n",
    "        .sort_index()\n",
    "    )\n",
    "\n",
    "    # build long/short portfolios on validation (net of transaction costs)\n",
    "    _, long_val, long_short_val = compute_cs_daily_returns(\n",
    "        df_val_live,\n",
    "        q=q,\n",
    "        horizon=lookahead,\n",
    "        cost_bps=COST_BPS,\n",
    "    )\n",
    "\n",
    "    ret_series = long_short_val.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    if len(ret_series) < 20:\n",
    "        return 0.0  # treat as bad if too little data\n",
    "\n",
    "    return -sharpe_ratio_np(ret_series.values)  # Optuna MINIMIZES\n",
    "\n",
    "study_live = optuna.create_study(direction=\"minimize\")\n",
    "study_live.optimize(objective_tree_live, n_trials=20)\n",
    "\n",
    "print(\"Best live params:\", study_live.best_params)\n",
    "print(\"Best live val -Sharpe:\", study_live.best_value)\n",
    "\n",
    "best_live = study_live.best_params.copy()\n",
    "q_live = best_live.pop(\"q\")\n",
    "\n",
    "# 3) Train final tree on ALL history before as_of_date\n",
    "tree_live = HistGradientBoostingRegressor(\n",
    "    **best_live,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "X_hist_live = X[hist_mask]\n",
    "y_hist_live = y[hist_mask]\n",
    "tree_live.fit(X_hist_live, y_hist_live)\n",
    "\n",
    "# 4) Predictions for the as-of date (our \"today\")\n",
    "live_mask = dates == as_of_date\n",
    "X_live = X[live_mask]\n",
    "tickers_live = tickers[live_mask]\n",
    "\n",
    "y_pred_live = tree_live.predict(X_live)\n",
    "\n",
    "panel_live = pd.DataFrame(\n",
    "    {\n",
    "        \"ticker\": tickers_live,\n",
    "        \"pred_fwd_21\": y_pred_live,   # model prediction: 21d total return (gross)\n",
    "    }\n",
    ").set_index(\"ticker\")\n",
    "\n",
    "# approximate net-of-fee 21d return for a long position\n",
    "panel_live[\"pred_fwd_21_net_long\"] = (1.0 + panel_live[\"pred_fwd_21\"]) * (1.0 - COST_BPS) - 1.0\n",
    "panel_live[\"pred_daily_net_long\"] = (1.0 + panel_live[\"pred_fwd_21_net_long\"]) ** (1.0 / lookahead) - 1.0\n",
    "\n",
    "# cross-sectional average daily net return (like EW benchmark)\n",
    "mean_daily_net = panel_live[\"pred_daily_net_long\"].mean()\n",
    "panel_live[\"edge_vs_eqw_daily\"] = panel_live[\"pred_daily_net_long\"] - mean_daily_net\n",
    "\n",
    "# 5) Sort and show top/bottom N\n",
    "panel_sorted = panel_live.sort_values(\"pred_fwd_21_net_long\", ascending=False)\n",
    "\n",
    "top_long  = panel_sorted.head(TOP_N_LONG).copy()\n",
    "bottom_short = panel_sorted.tail(TOP_N_SHORT).copy()\n",
    "\n",
    "print(\"\\n=== Paper-trade recommendation ===\")\n",
    "print(f\"As-of date: {as_of_date.date()}  |  lookahead: {lookahead} days\")\n",
    "print(\n",
    "    f\"Tuned q_live = {q_live:.3f}  \"\n",
    "    f\"(strategy would typically long/short ~{int(q_live * len(panel_sorted))} names per side)\"\n",
    ")\n",
    "print(f\"Assumed round-trip cost: {COST_BPS * 1e4:.1f} bps per 21d holding period\")\n",
    "\n",
    "print(\"\\nTop tickers to LONG (preview, net of costs):\")\n",
    "display(\n",
    "    top_long[\n",
    "        [\"pred_fwd_21\", \"pred_fwd_21_net_long\", \"pred_daily_net_long\", \"edge_vs_eqw_daily\"]\n",
    "    ].sort_values(\"pred_fwd_21_net_long\", ascending=False)\n",
    ")\n",
    "\n",
    "print(\"\\nBottom tickers to SHORT (preview, net of costs):\")\n",
    "# for shorts, a strongly negative predicted return is good\n",
    "display(\n",
    "    bottom_short[\n",
    "        [\"pred_fwd_21\", \"pred_fwd_21_net_long\", \"pred_daily_net_long\", \"edge_vs_eqw_daily\"]\n",
    "    ].sort_values(\"pred_fwd_21_net_long\")  # most negative first\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba674ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Final live model: global tuning on full history, then train once & save\n",
    "# =============================================================================\n",
    "\n",
    "# 1) Global train/validation split over all dates (for hyperparameter tuning)\n",
    "all_dates = np.array(sorted(dates.unique()))\n",
    "split_idx = int(len(all_dates) * 0.7)\n",
    "train_end_global = all_dates[split_idx]\n",
    "\n",
    "mask_train_global = dates <= train_end_global\n",
    "mask_val_global   = dates > train_end_global\n",
    "\n",
    "X_train_g, y_train_g = X[mask_train_global], y[mask_train_global]\n",
    "X_val_g,   y_val_g   = X[mask_val_global],   y[mask_val_global]\n",
    "\n",
    "dates_val_g   = dates[mask_val_global]\n",
    "tickers_val_g = tickers[mask_val_global]\n",
    "\n",
    "print(\"Global tuning:\")\n",
    "print(\"  Train dates:\", dates[mask_train_global].min(), \"->\", dates[mask_train_global].max())\n",
    "print(\"  Val   dates:\", dates_val_g.min(), \"->\", dates_val_g.max())\n",
    "print(\"  Train samples:\", len(y_train_g), \" Val samples:\", len(y_val_g))\n",
    "\n",
    "\n",
    "def objective_tree_global(trial):\n",
    "    # --- Tree hyperparameters ---\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 2, 8)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 0.2, log=True)\n",
    "    max_iter = trial.suggest_int(\"max_iter\", 100, 500)\n",
    "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 20, 200)\n",
    "    # long/short bucket size\n",
    "    q = trial.suggest_float(\"q\", 0.05, 0.3)\n",
    "\n",
    "    model = HistGradientBoostingRegressor(\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        max_iter=max_iter,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=42,\n",
    "    )\n",
    "    model.fit(X_train_g, y_train_g)\n",
    "\n",
    "    # Predictions on validation\n",
    "    y_pred_val = model.predict(X_val_g)\n",
    "\n",
    "    df_val_g = (\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"date\":   dates_val_g,\n",
    "                \"symbol\": tickers_val_g,\n",
    "                \"y_true\": y_val_g,\n",
    "                \"y_pred\": y_pred_val,\n",
    "            }\n",
    "        )\n",
    "        .set_index([\"date\", \"symbol\"])\n",
    "        .sort_index()\n",
    "    )\n",
    "\n",
    "    # Build long-only & long-short portfolios on validation, NET of costs\n",
    "    _, long_val_g, long_short_val_g = compute_cs_daily_returns(\n",
    "        df_val_g,\n",
    "        q=q,\n",
    "        horizon=lookahead,\n",
    "        cost_bps=COST_BPS,\n",
    "    )\n",
    "\n",
    "    # We optimize **long-only** net Sharpe (you can switch to long_short_val_g if you want)\n",
    "    ret_series = long_val_g.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    if len(ret_series) < 20:\n",
    "        return 0.0\n",
    "\n",
    "    return -sharpe_ratio_np(ret_series.values)\n",
    "\n",
    "\n",
    "study_global = optuna.create_study(direction=\"minimize\")\n",
    "study_global.optimize(objective_tree_global, n_trials=20)\n",
    "\n",
    "print(\"Global best params:\", study_global.best_params)\n",
    "print(\"Global best -Sharpe (long-only, net):\", study_global.best_value)\n",
    "\n",
    "best_params_live = study_global.best_params.copy()\n",
    "q_live = best_params_live.pop(\"q\")\n",
    "\n",
    "\n",
    "# 2) Train final model on ALL labeled history (X, y)\n",
    "tree_cs_final = HistGradientBoostingRegressor(\n",
    "    **best_params_live,\n",
    "    random_state=42,\n",
    ")\n",
    "tree_cs_final.fit(X, y)\n",
    "\n",
    "print(\"Final model trained on:\", dates.min(), \"->\", dates.max())\n",
    "print(\"Final model train R^2:\", tree_cs_final.score(X, y))\n",
    "\n",
    "\n",
    "# 3) Save bundle to disk for inference\n",
    "models_dir = Path(PROJECT_ROOT) / \"models\"\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "bundle = {\n",
    "    \"model\": tree_cs_final,\n",
    "    \"q_live\": q_live,\n",
    "    \"lookahead\": lookahead,\n",
    "    \"cost_bps\": COST_BPS,\n",
    "    \"features\": CROSS_FEATURES,\n",
    "    \"train_start\": str(dates.min().date()),\n",
    "    \"train_end\":   str(dates.max().date()),\n",
    "    \"optuna_best_params\": study_global.best_params,\n",
    "    \"optuna_best_value\":  float(study_global.best_value),\n",
    "}\n",
    "\n",
    "out_path = models_dir / \"sp500_tree_cs_21d_live.pkl\"\n",
    "joblib.dump(bundle, out_path)\n",
    "\n",
    "print(\"Saved live model bundle to:\", out_path)\n",
    "print(\"q_live (fraction of names long/short):\", q_live)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
