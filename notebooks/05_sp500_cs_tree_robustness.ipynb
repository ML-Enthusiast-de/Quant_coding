{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8475d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05_sp500_cs_tree_robustness.ipynb\n",
    "# Robustness of cross-sectional SP500 tree vs momentum across multiple test windows\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import optuna\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-darkgrid\")\n",
    "\n",
    "def sharpe_ratio_np(returns, freq: int = 252) -> float:\n",
    "    \"\"\"Simple annualized Sharpe on a 1D array of daily returns.\"\"\"\n",
    "    r = np.asarray(returns, dtype=float)\n",
    "    if r.size == 0 or np.isclose(r.std(), 0.0):\n",
    "        return 0.0\n",
    "    return np.sqrt(freq) * r.mean() / r.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e9c09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = os.path.abspath(\"..\")\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.data_loading_cross import load_sp500_adj_close\n",
    "from src.signals_cross import (\n",
    "    make_cross_sectional_signals,\n",
    "    build_cross_sectional_matrix,\n",
    "    CROSS_FEATURES,\n",
    ")\n",
    "\n",
    "from src.backtest import (\n",
    "    equity_curve_from_returns,\n",
    "    cagr,\n",
    "    annualized_vol,\n",
    "    sharpe_ratio,\n",
    "    max_drawdown,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a8a167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Global transaction cost setting ---\n",
    "# round-trip cost as a fraction of notional per 21-day \"trade\"\n",
    "# 0.0005 = 5 bps, 0.001 = 10 bps, etc.\n",
    "COST_BPS = 0.001  # tweak this to whatever you want to assume\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b843fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SP500 panel as long as we can reasonably go\n",
    "# (set force_download=True the first time if needed)\n",
    "prices = load_sp500_adj_close(start=\"2000-01-01\")\n",
    "\n",
    "prices.info()\n",
    "print(\"Price panel shape:\", prices.shape)\n",
    "print(\"Date range:\", prices.index.min(), \"->\", prices.index.max())\n",
    "print(\"Number of tickers:\", len(prices.columns))\n",
    "\n",
    "lookahead = 21  # ~1 month forward return\n",
    "\n",
    "signals_df = make_cross_sectional_signals(prices, lookahead=lookahead)\n",
    "\n",
    "print(\"Signals shape:\", signals_df.shape)\n",
    "print(\"Columns:\", signals_df.columns.tolist())\n",
    "\n",
    "dates_all = signals_df.index.get_level_values(\"date\")\n",
    "tickers_all = signals_df.index.get_level_values(\"ticker\")\n",
    "\n",
    "print(\"Signals date range:\", dates_all.min(), \"->\", dates_all.max())\n",
    "print(\"Unique tickers in signals:\", len(np.unique(tickers_all)))\n",
    "\n",
    "# Build big (X, y, dates, tickers) matrix\n",
    "X, y, dates, tickers = build_cross_sectional_matrix(signals_df)\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "print(\"Feature names:\", CROSS_FEATURES)\n",
    "print(\"Min/max date:\", dates.min(), \"->\", dates.max())\n",
    "print(\"Num unique tickers:\", np.unique(tickers).size)\n",
    "\n",
    "# Quick sanity check on forward-return distribution\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(y, bins=100)\n",
    "plt.title(f\"Distribution of {lookahead}-day forward returns\")\n",
    "plt.xlabel(\"Forward return\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcb825f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_momentum_cs(\n",
    "    group: pd.DataFrame,\n",
    "    q: float = 0.1,\n",
    "    horizon: int = 21,\n",
    "    cost_bps: float = 0.0,\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Cross-sectional momentum for a single date.\n",
    "\n",
    "    group: rows for one date, many tickers.\n",
    "    q: top/bottom quantile, e.g. 0.1 for deciles.\n",
    "    horizon: forward horizon used for the target (e.g. 21 days).\n",
    "    cost_bps: round-trip cost per 21-day position (same meaning as above).\n",
    "    \"\"\"\n",
    "    n = len(group)\n",
    "    if n < 10:\n",
    "        return pd.Series({\"eqw\": 0.0, \"long\": 0.0, \"long_short\": 0.0})\n",
    "\n",
    "    # equal-weight all stocks -> \"index\" (21-day return, frictionless)\n",
    "    eqw_ret_21 = group[\"target_fwd_21\"].mean()\n",
    "\n",
    "    # sort by past 21d return (classical cross-sectional momentum)\n",
    "    g_sorted = group.sort_values(\"ret_21\")\n",
    "    k = max(1, int(n * q))\n",
    "\n",
    "    bottom = g_sorted.iloc[:k]\n",
    "    top    = g_sorted.iloc[-k:]\n",
    "\n",
    "    long_ret_21  = top[\"target_fwd_21\"].mean()\n",
    "    short_ret_21 = bottom[\"target_fwd_21\"].mean()\n",
    "    long_short_21 = long_ret_21 - short_ret_21\n",
    "\n",
    "    # Apply transaction costs on 21-day horizon\n",
    "    if cost_bps > 0.0:\n",
    "        long_ret_21   = (1.0 + long_ret_21) * (1.0 - cost_bps) - 1.0\n",
    "        long_short_21 = (1.0 + long_short_21) * (1.0 - 2.0 * cost_bps) - 1.0\n",
    "\n",
    "    # convert to daily\n",
    "    def to_daily(R):\n",
    "        return (1.0 + R) ** (1.0 / horizon) - 1.0\n",
    "\n",
    "    eqw_ret_daily   = to_daily(eqw_ret_21)\n",
    "    long_ret_daily  = to_daily(long_ret_21)\n",
    "    long_short_daily = to_daily(long_short_21)\n",
    "\n",
    "    return pd.Series(\n",
    "        {\n",
    "            \"eqw\": eqw_ret_daily,\n",
    "            \"long\": long_ret_daily,\n",
    "            \"long_short\": long_short_daily,\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "def compute_cs_daily_returns(\n",
    "    df: pd.DataFrame,\n",
    "    q: float = 0.1,\n",
    "    horizon: int = 21,\n",
    "    cost_bps: float = 0.0,\n",
    "):\n",
    "    \"\"\"\n",
    "    df: index (date, symbol), columns: y_true, y_pred (21d fwd returns + predictions)\n",
    "    Returns three Series of *daily-equivalent* returns:\n",
    "        eqw, long-only (top q), long-short (top q minus bottom q)\n",
    "\n",
    "    cost_bps:\n",
    "        round-trip transaction cost per 21-day holding period as fraction\n",
    "        e.g. 0.0005 = 5 bps, 0.001 = 10 bps.\n",
    "        Applied once for a long-only position and twice for a long-short position.\n",
    "    \"\"\"\n",
    "\n",
    "    def _per_date(group: pd.DataFrame) -> pd.Series:\n",
    "        n = len(group)\n",
    "        if n < 10:\n",
    "            return pd.Series({\"eqw\": 0.0, \"long\": 0.0, \"long_short\": 0.0})\n",
    "\n",
    "        # Equal-weight all stocks -> benchmark (frictionless)\n",
    "        eqw_ret_21 = group[\"y_true\"].mean()\n",
    "\n",
    "        # Sort by predicted forward return\n",
    "        g_sorted = group.sort_values(\"y_pred\")\n",
    "        k = max(1, int(n * q))\n",
    "\n",
    "        bottom = g_sorted.iloc[:k]     # worst predicted\n",
    "        top    = g_sorted.iloc[-k:]    # best predicted\n",
    "\n",
    "        long_ret_21  = top[\"y_true\"].mean()\n",
    "        short_ret_21 = bottom[\"y_true\"].mean()\n",
    "\n",
    "        # 21d long-short return before costs\n",
    "        long_short_21 = long_ret_21 - short_ret_21\n",
    "\n",
    "        # --- Apply transaction costs on the 21-day horizon ---\n",
    "        # long-only: 1 round-trip -> cost_bps\n",
    "        # long-short: 2 round-trips (long + short) -> 2 * cost_bps\n",
    "        if cost_bps > 0.0:\n",
    "            long_ret_21      = (1.0 + long_ret_21) * (1.0 - cost_bps) - 1.0\n",
    "            long_short_21    = (1.0 + long_short_21) * (1.0 - 2.0 * cost_bps) - 1.0\n",
    "\n",
    "        # convert 21-day returns to daily-equivalent\n",
    "        def to_daily(R):\n",
    "            return (1.0 + R) ** (1.0 / horizon) - 1.0\n",
    "\n",
    "        eqw_daily        = to_daily(eqw_ret_21)\n",
    "        long_daily       = to_daily(long_ret_21)\n",
    "        long_short_daily = to_daily(long_short_21)\n",
    "\n",
    "        return pd.Series(\n",
    "            {\"eqw\": eqw_daily, \"long\": long_daily, \"long_short\": long_short_daily}\n",
    "        )\n",
    "\n",
    "    daily = df.groupby(\"date\").apply(_per_date)\n",
    "\n",
    "    eqw = daily[\"eqw\"].astype(float)\n",
    "    long = daily[\"long\"].astype(float)\n",
    "    long_short = daily[\"long_short\"].astype(float)\n",
    "\n",
    "    return eqw, long, long_short\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63770b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cs_daily_returns_gated(\n",
    "    df: pd.DataFrame,\n",
    "    q: float = 0.1,\n",
    "    horizon: int = 21,\n",
    "    cost_bps: float = 0.0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Like compute_cs_daily_returns, but:\n",
    "    - uses model predictions to decide whether to trade at all,\n",
    "    - only applies costs on days where we actually trade.\n",
    "\n",
    "    df: index (date, symbol), columns: y_true, y_pred\n",
    "    \"\"\"\n",
    "\n",
    "    def _per_date(group: pd.DataFrame) -> pd.Series:\n",
    "        n = len(group)\n",
    "        if n < 10:\n",
    "            return pd.Series({\"eqw\": 0.0, \"long\": 0.0, \"long_short\": 0.0})\n",
    "\n",
    "        # Benchmark: equal-weight all stocks (no costs)\n",
    "        eqw_ret_21 = group[\"y_true\"].mean()\n",
    "\n",
    "        # Rank by predicted forward return\n",
    "        g_sorted = group.sort_values(\"y_pred\")\n",
    "        k = max(1, int(n * q))\n",
    "\n",
    "        bottom = g_sorted.iloc[:k]\n",
    "        top    = g_sorted.iloc[-k:]\n",
    "\n",
    "        # --- True 21d returns (what actually happens) ---\n",
    "        long_true_21  = top[\"y_true\"].mean()\n",
    "        short_true_21 = bottom[\"y_true\"].mean()\n",
    "        long_short_true_21 = long_true_21 - short_true_21\n",
    "\n",
    "        # --- Predicted 21d returns (model view) ---\n",
    "        long_pred_21  = top[\"y_pred\"].mean()\n",
    "        short_pred_21 = bottom[\"y_pred\"].mean()\n",
    "        long_short_pred_21 = long_pred_21 - short_pred_21\n",
    "\n",
    "        # ---- Decision: do we trade? ----\n",
    "        # Long-only: require predicted edge > cost\n",
    "        trade_long = long_pred_21 > cost_bps\n",
    "\n",
    "        # Long-short: require predicted spread > 2 * cost\n",
    "        trade_ls   = long_short_pred_21 > 2.0 * cost_bps\n",
    "\n",
    "        # Start from \"no trade\"\n",
    "        long_ret_21      = 0.0\n",
    "        long_short_21    = 0.0\n",
    "\n",
    "        if trade_long:\n",
    "            long_ret_21 = long_true_21\n",
    "\n",
    "        if trade_ls:\n",
    "            long_short_21 = long_short_true_21\n",
    "\n",
    "        # ---- Apply costs only if we actually trade ----\n",
    "        if cost_bps > 0.0 and trade_long:\n",
    "            long_ret_21 = (1.0 + long_ret_21) * (1.0 - cost_bps) - 1.0\n",
    "\n",
    "        if cost_bps > 0.0 and trade_ls:\n",
    "            long_short_21 = (1.0 + long_short_21) * (1.0 - 2.0 * cost_bps) - 1.0\n",
    "\n",
    "        # Convert 21-day returns to daily-equivalent\n",
    "        def to_daily(R):\n",
    "            return (1.0 + R) ** (1.0 / horizon) - 1.0\n",
    "\n",
    "        eqw_daily        = to_daily(eqw_ret_21)\n",
    "        long_daily       = to_daily(long_ret_21)\n",
    "        long_short_daily = to_daily(long_short_21)\n",
    "\n",
    "        return pd.Series(\n",
    "            {\"eqw\": eqw_daily, \"long\": long_daily, \"long_short\": long_short_daily}\n",
    "        )\n",
    "\n",
    "    daily = df.groupby(\"date\").apply(_per_date)\n",
    "\n",
    "    eqw = daily[\"eqw\"].astype(float)\n",
    "    long = daily[\"long\"].astype(float)\n",
    "    long_short = daily[\"long_short\"].astype(float)\n",
    "\n",
    "    return eqw, long, long_short\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e89bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cs_window(\n",
    "    test_start: str,\n",
    "    test_end: str,\n",
    "    n_trials: int = 10,\n",
    "    q_mom: float = 0.1,\n",
    "    random_state: int = 42,\n",
    "):\n",
    "    \"\"\"\n",
    "    Run the full pipeline for a single test window:\n",
    "    - Train/val on data *before* test_start\n",
    "    - Tune tree + q on validation long-short Sharpe (net of costs)\n",
    "    - Evaluate momentum and tree on [test_start, test_end] (net of costs)\n",
    "    \"\"\"\n",
    "    test_start = pd.Timestamp(test_start)\n",
    "    test_end   = pd.Timestamp(test_end)\n",
    "\n",
    "    # Masks for this window\n",
    "    test_mask = (dates >= test_start) & (dates <= test_end)\n",
    "    hist_mask = dates < test_start\n",
    "\n",
    "    if test_mask.sum() == 0 or hist_mask.sum() < 1000:\n",
    "        print(f\"Skipping window {test_start.date()}–{test_end.date()} (not enough data).\")\n",
    "        return None\n",
    "\n",
    "    hist_dates = np.array(sorted(dates[hist_mask].unique()))\n",
    "    # 70/30 split of *history* into train/val\n",
    "    train_end_local = hist_dates[int(len(hist_dates) * 0.7)]\n",
    "\n",
    "    train_mask = (dates <= train_end_local)\n",
    "    val_mask   = (dates > train_end_local) & (dates < test_start)\n",
    "\n",
    "    X_train, y_train = X[train_mask], y[train_mask]\n",
    "    X_val,   y_val   = X[val_mask],   y[val_mask]\n",
    "    X_test,  y_test  = X[test_mask],  y[test_mask]\n",
    "\n",
    "    dates_val_local    = dates[val_mask]\n",
    "    dates_test_local   = dates[test_mask]\n",
    "    tickers_val_local  = tickers[val_mask]\n",
    "    tickers_test_local = tickers[test_mask]\n",
    "\n",
    "    print(\n",
    "        f\"Window {test_start.date()}–{test_end.date()} | \"\n",
    "        f\"train={len(y_train)}, val={len(y_val)}, test={len(y_test)}\"\n",
    "    )\n",
    "\n",
    "    # -------------------------\n",
    "    # Optuna objective for this window (tree + q, net-of-cost Sharpe)\n",
    "    # -------------------------\n",
    "    def objective_tree_cs(trial):\n",
    "        max_depth = trial.suggest_int(\"max_depth\", 2, 8)\n",
    "        learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 0.2, log=True)\n",
    "        max_iter = trial.suggest_int(\"max_iter\", 100, 500)\n",
    "        min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 20, 200)\n",
    "\n",
    "        q = trial.suggest_float(\"q\", 0.05, 0.3)  # top/bottom 5–30%\n",
    "\n",
    "        model = HistGradientBoostingRegressor(\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            max_iter=max_iter,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_val = model.predict(X_val)\n",
    "\n",
    "        df_val = pd.DataFrame(\n",
    "            {\n",
    "                \"date\":   dates_val_local,\n",
    "                \"symbol\": tickers_val_local,\n",
    "                \"y_true\": y_val,\n",
    "                \"y_pred\": y_pred_val,\n",
    "            }\n",
    "        ).set_index([\"date\", \"symbol\"]).sort_index()\n",
    "\n",
    "        # Build portfolios on validation (net of costs)\n",
    "\n",
    "\n",
    "        _, long_val, long_short_val = compute_cs_daily_returns_gated(\n",
    "            df_val,\n",
    "            q=q,\n",
    "            horizon=lookahead,\n",
    "            cost_bps=COST_BPS,\n",
    "        )\n",
    "\n",
    "\n",
    "        ret_series = long_short_val.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "        if len(ret_series) < 20:\n",
    "            return 0.0\n",
    "\n",
    "        return -sharpe_ratio_np(ret_series.values)\n",
    "\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective_tree_cs, n_trials=n_trials)\n",
    "\n",
    "    print(\"  Best params:\", study.best_params)\n",
    "    print(\"  Best val -Sharpe:\", study.best_value)\n",
    "\n",
    "    best_params = study.best_params.copy()\n",
    "    q_best = best_params.pop(\"q\")\n",
    "\n",
    "    tree_best = HistGradientBoostingRegressor(\n",
    "        **best_params,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "\n",
    "    # Train on all history (train+val) prior to test_start\n",
    "    hist_mask_full = dates < test_start\n",
    "    X_hist, y_hist = X[hist_mask_full], y[hist_mask_full]\n",
    "    tree_best.fit(X_hist, y_hist)\n",
    "\n",
    "    # -------------------------\n",
    "    # Evaluate on TEST window\n",
    "    # -------------------------\n",
    "\n",
    "    # 1) Momentum baseline on this test window (net of costs)\n",
    "    idx_dates = signals_df.index.get_level_values(\"date\")\n",
    "    signals_test = signals_df.loc[\n",
    "        (idx_dates >= test_start) & (idx_dates <= test_end)\n",
    "    ].copy()\n",
    "\n",
    "    daily_mom = signals_test.groupby(\"date\").apply(\n",
    "        daily_momentum_cs,\n",
    "        q=q_mom,\n",
    "        horizon=lookahead,\n",
    "        cost_bps=COST_BPS,\n",
    "    )\n",
    "\n",
    "    eqw_returns   = daily_mom[\"eqw\"].astype(float)\n",
    "    momL_returns  = daily_mom[\"long\"].astype(float)\n",
    "    momLS_returns = daily_mom[\"long_short\"].astype(float)\n",
    "\n",
    "\n",
    "    # 2) Tree strategy on this test window (net of costs)\n",
    "    y_pred_test = tree_best.predict(X_test)\n",
    "\n",
    "    df_test = pd.DataFrame(\n",
    "        {\n",
    "            \"date\":   dates_test_local,\n",
    "            \"symbol\": tickers_test_local,\n",
    "            \"y_true\": y_test,\n",
    "            \"y_pred\": y_pred_test,\n",
    "        }\n",
    "    ).set_index([\"date\", \"symbol\"]).sort_index()\n",
    "\n",
    "\n",
    "\n",
    "    _, treeL_returns, treeLS_returns = compute_cs_daily_returns_gated(\n",
    "    df_test,\n",
    "    q=q_best,\n",
    "    horizon=lookahead,\n",
    "    cost_bps=COST_BPS,\n",
    "    )\n",
    "\n",
    "\n",
    "    # 3) Equity curves + metrics\n",
    "    eqw_eq    = equity_curve_from_returns(eqw_returns)\n",
    "    momL_eq   = equity_curve_from_returns(momL_returns)\n",
    "    momLS_eq  = equity_curve_from_returns(momLS_returns)\n",
    "    treeL_eq  = equity_curve_from_returns(treeL_returns)\n",
    "    treeLS_eq = equity_curve_from_returns(treeLS_returns)\n",
    "\n",
    "    metrics = {\n",
    "        \"test_start\": test_start.date(),\n",
    "        \"test_end\":   test_end.date(),\n",
    "\n",
    "        \"momL_cagr\":    cagr(momL_eq),\n",
    "        \"momL_sharpe\":  sharpe_ratio(momL_returns),\n",
    "        \"momL_max_dd\":  max_drawdown(momL_eq),\n",
    "\n",
    "        \"treeL_cagr\":   cagr(treeL_eq),\n",
    "        \"treeL_sharpe\": sharpe_ratio(treeL_returns),\n",
    "        \"treeL_max_dd\": max_drawdown(treeL_eq),\n",
    "\n",
    "        \"momLS_cagr\":   cagr(momLS_eq),\n",
    "        \"momLS_sharpe\": sharpe_ratio(momLS_returns),\n",
    "        \"momLS_max_dd\": max_drawdown(momLS_eq),\n",
    "\n",
    "        \"treeLS_cagr\":   cagr(treeLS_eq),\n",
    "        \"treeLS_sharpe\": sharpe_ratio(treeLS_returns),\n",
    "        \"treeLS_max_dd\": max_drawdown(treeLS_eq),\n",
    "    }\n",
    "\n",
    "    # quick plots for this window\n",
    "    plt.figure(figsize=(9, 4))\n",
    "    momL_eq.plot(label=\"Momentum long-only\")\n",
    "    treeL_eq.plot(label=\"Tree long-only (Optuna)\")\n",
    "    plt.legend()\n",
    "    plt.title(f\"Long-only (net costs): {test_start.date()}–{test_end.date()}\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(9, 4))\n",
    "    momLS_eq.plot(label=\"Momentum long-short\")\n",
    "    treeLS_eq.plot(label=\"Tree long-short (Optuna)\")\n",
    "    plt.legend()\n",
    "    plt.title(f\"Long-short (net costs): {test_start.date()}–{test_end.date()}\")\n",
    "    plt.show()\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933a6b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose several non-overlapping test windows.\n",
    "# Training/validation for each window uses *only data before* test_start.\n",
    "test_windows = [\n",
    "    (\"2005-01-01\", \"2009-12-31\"),\n",
    "    (\"2010-01-01\", \"2014-12-31\"),\n",
    "    (\"2015-01-01\", \"2019-12-31\"),\n",
    "    (\"2020-01-01\", \"2024-12-31\"),\n",
    "]\n",
    "test_windows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997a00bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for start, end in test_windows:\n",
    "    print(\"=\" * 80)\n",
    "    m = run_cs_window(start, end, n_trials=10, q_mom=0.1)\n",
    "    if m is not None:\n",
    "        results.append(m)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d01625",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_cols = [\n",
    "    \"test_start\", \"test_end\",\n",
    "    \"momL_sharpe\", \"treeL_sharpe\",\n",
    "    \"momLS_sharpe\", \"treeLS_sharpe\",\n",
    "]\n",
    "\n",
    "summary = results_df[summary_cols].copy()\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8602d97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary[\"treeL_minus_momL\"]   = summary[\"treeL_sharpe\"]  - summary[\"momL_sharpe\"]\n",
    "summary[\"treeLS_minus_momLS\"] = summary[\"treeLS_sharpe\"] - summary[\"momLS_sharpe\"]\n",
    "\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48c7384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nice labels for windows\n",
    "window_labels = (\n",
    "    results_df[\"test_start\"].astype(str)\n",
    "    + \"–\"\n",
    "    + results_df[\"test_end\"].astype(str)\n",
    ")\n",
    "x = np.arange(len(results_df))\n",
    "width = 0.35\n",
    "\n",
    "# --- Long-only Sharpe: momentum vs tree ---\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.bar(x - width/2, results_df[\"momL_sharpe\"], width, label=\"Momentum long-only\")\n",
    "plt.bar(x + width/2, results_df[\"treeL_sharpe\"], width, label=\"Tree long-only (Optuna)\")\n",
    "plt.xticks(x, window_labels, rotation=30, ha=\"right\")\n",
    "plt.ylabel(\"Sharpe\")\n",
    "plt.title(\"Long-only Sharpe by test window\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Long-short Sharpe: momentum vs tree ---\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.bar(x - width/2, results_df[\"momLS_sharpe\"], width, label=\"Momentum long-short\")\n",
    "plt.bar(x + width/2, results_df[\"treeLS_sharpe\"], width, label=\"Tree long-short (Optuna)\")\n",
    "plt.xticks(x, window_labels, rotation=30, ha=\"right\")\n",
    "plt.ylabel(\"Sharpe\")\n",
    "plt.title(\"Long-short Sharpe by test window\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1576cf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add differences if not already there\n",
    "results_df[\"treeL_minus_momL\"]   = results_df[\"treeL_sharpe\"]  - results_df[\"momL_sharpe\"]\n",
    "results_df[\"treeLS_minus_momLS\"] = results_df[\"treeLS_sharpe\"] - results_df[\"momLS_sharpe\"]\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.bar(x, results_df[\"treeL_minus_momL\"])\n",
    "plt.axhline(0, color=\"black\", linewidth=1)\n",
    "plt.xticks(x, window_labels, rotation=30, ha=\"right\")\n",
    "plt.ylabel(\"Δ Sharpe (tree - momentum)\")\n",
    "plt.title(\"Long-only: tree vs momentum Sharpe per window\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.bar(x, results_df[\"treeLS_minus_momLS\"])\n",
    "plt.axhline(0, color=\"black\", linewidth=1)\n",
    "plt.xticks(x, window_labels, rotation=30, ha=\"right\")\n",
    "plt.ylabel(\"Δ Sharpe (tree - momentum)\")\n",
    "plt.title(\"Long-short: tree vs momentum Sharpe per window\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cdc547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Long-only scatter\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(results_df[\"momL_sharpe\"], results_df[\"treeL_sharpe\"])\n",
    "lims = [\n",
    "    min(results_df[\"momL_sharpe\"].min(), results_df[\"treeL_sharpe\"].min()) - 0.2,\n",
    "    max(results_df[\"momL_sharpe\"].max(), results_df[\"treeL_sharpe\"].max()) + 0.2,\n",
    "]\n",
    "plt.plot(lims, lims, \"--\", color=\"gray\")  # y = x line\n",
    "for i, label in enumerate(window_labels):\n",
    "    plt.text(\n",
    "        results_df[\"momL_sharpe\"].iloc[i] + 0.02,\n",
    "        results_df[\"treeL_sharpe\"].iloc[i] + 0.02,\n",
    "        label,\n",
    "        fontsize=8,\n",
    "    )\n",
    "plt.xlim(lims)\n",
    "plt.ylim(lims)\n",
    "plt.xlabel(\"Momentum long-only Sharpe\")\n",
    "plt.ylabel(\"Tree long-only Sharpe\")\n",
    "plt.title(\"Long-only: tree vs momentum Sharpe across windows\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Long-short scatter\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(results_df[\"momLS_sharpe\"], results_df[\"treeLS_sharpe\"])\n",
    "lims = [\n",
    "    min(results_df[\"momLS_sharpe\"].min(), results_df[\"treeLS_sharpe\"].min()) - 0.2,\n",
    "    max(results_df[\"momLS_sharpe\"].max(), results_df[\"treeLS_sharpe\"].max()) + 0.2,\n",
    "]\n",
    "plt.plot(lims, lims, \"--\", color=\"gray\")\n",
    "for i, label in enumerate(window_labels):\n",
    "    plt.text(\n",
    "        results_df[\"momLS_sharpe\"].iloc[i] + 0.02,\n",
    "        results_df[\"treeLS_sharpe\"].iloc[i] + 0.02,\n",
    "        label,\n",
    "        fontsize=8,\n",
    "    )\n",
    "plt.xlim(lims)\n",
    "plt.ylim(lims)\n",
    "plt.xlabel(\"Momentum long-short Sharpe\")\n",
    "plt.ylabel(\"Tree long-short Sharpe\")\n",
    "plt.title(\"Long-short: tree vs momentum Sharpe across windows\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
